{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get document frequency for terms in the same article/instance; and get each sentence's BOW; and get each question's BOW;\n",
    "#get each sentence's length; get each article's average length of sentences\n",
    "import csv\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "import nltk\n",
    "import sys \n",
    "import math\n",
    "import operator\n",
    "import re\n",
    "import string\n",
    "from math import log\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.spatial.distance import cosine as cos_distance\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "def get_BOW(text):\n",
    "    BOW = {}\n",
    "    for word in text:\n",
    "        BOW[word] = BOW.get(word,0) + 1\n",
    "    return BOW\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "def input_data():\n",
    "    base_path = os.path.join('data/')\n",
    "    train_file = base_path + 'QA_train.json'\n",
    "    train_data = json.load(open(train_file))\n",
    "    test_file = base_path + 'QA_test.json'\n",
    "    test_data = json.load(open(test_file))\n",
    "    dev_file = base_path + 'QA_dev.json'\n",
    "    dev_data = json.load(open(dev_file))\n",
    "\n",
    "    return train_data,test_data,dev_data\n",
    "def transform_text(text):\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [lemmatize(word.lower()) for word in text]\n",
    "    result = []\n",
    "    for word in text:\n",
    "        if word not in stopwords and word not in punctuations:\n",
    "            result.append(word)\n",
    "    return result\n",
    "def get_Docfrequency_SentenceBOW(dataset):\n",
    "    #save dics, each dictionary contains document frequencies for all terms in the same article\n",
    "    question_list = []\n",
    "    #save lists, each list represent an article, saving sentences' bow\n",
    "    total_sentence_bow = []\n",
    "    #save lists, each list represent an article, saving questions' bow\n",
    "    total_question_bow = []\n",
    "    #save lists, each list represent all sentences' lengthes.\n",
    "    sent_lengthes = []\n",
    "    #save a list, each item represents the average length of sentences\n",
    "    avg_lengthes = []\n",
    "    #\n",
    "    answer_id = []\n",
    "    \n",
    "    for article in dataset:\n",
    "        #Docfrequency\n",
    "        article_dic = defaultdict(list)\n",
    "        keyterms = [] #save all distinct terms in questions\n",
    "        \n",
    "        #SentenceBOW\n",
    "        bow_list = []\n",
    "        \n",
    "        #QuestionBOW\n",
    "        que_list = []\n",
    "        \n",
    "        #SentenceLength\n",
    "        sent_len = []\n",
    "        \n",
    "        #TotalLength\n",
    "        total_len = 0\n",
    "        \n",
    "        qas = article['qa']\n",
    "        sentences = article['sentences']\n",
    "        for qa in qas:\n",
    "            question = qa['question']\n",
    "            newquestion = transform_text(question)\n",
    "            #QuestionBOW\n",
    "            que_list.append(get_BOW(newquestion))\n",
    "            \n",
    "            keyterms.extend(newquestion)\n",
    "        keyterms = set(keyterms)\n",
    "        \n",
    "        #save sentences' BOW in list sen_BOW\n",
    "        sen_words = []\n",
    "        for sent in sentences:\n",
    "            sent = transform_text(sent)\n",
    "            #Docfrequency\n",
    "            sen_words.append(sent)\n",
    "            \n",
    "            #SentenceBOW\n",
    "            bow_list.append(get_BOW(sent))\n",
    "            \n",
    "            #SentenceLength\n",
    "            sent_len.append(len(sent))\n",
    "            \n",
    "            #TotalLength\n",
    "            total_len += len(sent)\n",
    "            \n",
    "        \n",
    "        #calculate doc frequency    \n",
    "        for term in keyterms:\n",
    "            for i,bow in enumerate(sen_words):\n",
    "                if term in bow:\n",
    "                    article_dic[term].append(i)\n",
    "                    \n",
    "        #Docfrequency\n",
    "        question_list.append(article_dic)\n",
    "        #SentenceBOW\n",
    "        total_sentence_bow.append(bow_list)\n",
    "        #QuestionBOW\n",
    "        total_question_bow.append(que_list)\n",
    "        #SentenceLength\n",
    "        sent_lengthes.append(sent_len)\n",
    "        #AverageLength\n",
    "        avg_lengthes.append(float(total_len)/len(sentences))\n",
    "\n",
    "        \n",
    "    return question_list, total_sentence_bow, total_question_bow, sent_lengthes, avg_lengthes\n",
    "\n",
    "train,test,dev = input_data()\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "punctuations = [',','\\'\\'','?','\\'','.','%','(',')',';','``']\n",
    "question_list, total_sentence_bow, total_question_bow, sent_lengthes, avg_lengthes = get_Docfrequency_SentenceBOW(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "def BM25_n(articles_index,k1,k2,b,n):\n",
    "    total_queries = len(total_question_bow[articles_index])\n",
    "    count = 0\n",
    "    correct_id = []\n",
    "    correct_id_weight = []\n",
    "    for index in range(len(total_question_bow[articles_index])):\n",
    "        poss_results = find_max_n_sentences(articles_index,index,k1,k2,b,n)\n",
    "        guess_ids = []\n",
    "        weights = []\n",
    "        for sent in poss_results:\n",
    "            guess_ids.append(sent[0])\n",
    "            weights.append(sent[1])\n",
    "        correct_id.append(guess_ids)\n",
    "        correct_id_weight.append(weights)\n",
    "    return correct_id,correct_id_weight\n",
    "\n",
    "def find_max_n_sentences(articles_index,index,k1,k2,b,n):\n",
    "    query_dict = total_question_bow[articles_index][index]\n",
    "    scores = {}\n",
    "    for index in range(len(total_sentence_bow[articles_index])):     \n",
    "        score = 0  \n",
    "        sentence_dict = total_sentence_bow[articles_index][index]\n",
    "        for word in query_dict:\n",
    "            document_fre_list = question_list[articles_index].get(word,None)\n",
    "            N = len(total_sentence_bow[articles_index])\n",
    "            n_qi = 0\n",
    "            if document_fre_list != None:\n",
    "                n_qi = len(document_fre_list)\n",
    "            else:\n",
    "                n_qi = 0\n",
    "            fi = sentence_dict.get(word,0)\n",
    "            qfi = query_dict.get(word,0)\n",
    "            dl = sent_lengthes[articles_index][index]\n",
    "            avgdl = avg_lengthes[articles_index]\n",
    "            \n",
    "            K = k1*(1-b+b*(float(dl)/avgdl)) \n",
    "            W = math.log((N-n_qi+0.5)/(n_qi+0.5))\n",
    "            R = (fi*(k1+1))/(fi+K)*qfi*(k2+1)/(qfi+k2)\n",
    "            score += W*R\n",
    "        scores[index] = score\n",
    "    scores = sorted(scores.items(), key=operator.itemgetter(1),reverse=True)[:n]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k1_list = [0.78]\n",
    "k2_list = [0]\n",
    "b_list = [0.5]\n",
    "\n",
    "result_sentences = []\n",
    "result_sentences_weight = []\n",
    "test_length = len(test)\n",
    "for k1 in k1_list:\n",
    "    for k2 in k2_list:\n",
    "        for b in b_list:\n",
    "            for i in range(0,test_length):\n",
    "                #the amount of extract sentences\n",
    "                amount = 4\n",
    "                correct_id,correct_id_weight = BM25_n(i,k1,k2,b,amount)\n",
    "                result_sentences.append(correct_id)\n",
    "                result_sentences_weight.append(correct_id_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NER\n",
    "'''\n",
    "time_word = [\n",
    "    'one','two','three','four','five','six','seven','eight','nine',\n",
    "    'January','February','March','April','May','June','July','August','September','October','November','December',\n",
    "    'million','billion',\n",
    "    'minutes','hours','years','times',\n",
    "    'mm','miles','inches','foot','feet',\n",
    "    'late','early','around','over',\n",
    "    'persons','seasons','square',\n",
    "    'spring','summer','fall','autumn','winter'\n",
    "]\n",
    "\n",
    "location_word = [\n",
    "    'southwest','southeast','northwest','northeast'\n",
    "]\n",
    "\n",
    "conjunction_word = ['and','of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_NER():\n",
    "    stanford_dir = os.path.join('stanford-ner-2016-10-31')\n",
    "    jarfile = os.path.join(stanford_dir,'stanford-ner.jar')\n",
    "    modelfile = os.path.join(stanford_dir,'classifiers/english.all.3class.distsim.crf.ser.gz')\n",
    "    return modelfile,jarfile\n",
    "model,jar = input_NER()\n",
    "st = StanfordNERTagger(model,jar)\n",
    "\n",
    "def analyse_NER(ner_sentences):\n",
    "    result_sentences = []\n",
    "    for ner_sentence in ner_sentences:\n",
    "        result_sentence = []\n",
    "        perv_type = u'O'\n",
    "        word = u''\n",
    "        conjunction = u''\n",
    "        conjunc_flag = False\n",
    "        for index,(entity,etype) in enumerate(ner_sentence):\n",
    "            if perv_type == u'O' and etype != u'O':              \n",
    "                perv_type = etype\n",
    "                word = entity + u' '\n",
    "            elif word != u'':\n",
    "                if etype == u'O':\n",
    "                    if entity not in conjunction_word:\n",
    "                        result_sentence.append((word[:-1],perv_type))\n",
    "                        word = u''\n",
    "                        perv_type = u'O'\n",
    "                        if conjunction != u'':\n",
    "                            conjunction = u''\n",
    "                            conjunc_flag = False\n",
    "                    else:\n",
    "                        if conjunction != u'':\n",
    "                            conjunction = u''\n",
    "                            conjunc_flag = False\n",
    "                        else:\n",
    "                            conjunction = entity\n",
    "                            conjunc_flag = True\n",
    "                elif etype != perv_type:\n",
    "                    result_sentence.append((word[:-1],perv_type))\n",
    "                    word = entity + u' '\n",
    "                    perv_type = etype\n",
    "                    conjunction = u''\n",
    "                    conjunc_flag = False\n",
    "                elif etype == perv_type:\n",
    "                    if conjunc_flag:\n",
    "                        if conjunction == u',':\n",
    "                            word = word[:-1] + conjunction + u' ' + entity + u' '\n",
    "                        else:\n",
    "                            word = word + conjunction + u' ' + entity + u' '\n",
    "                        conjunction = u''\n",
    "                        conjunc_flag = False\n",
    "                    else:\n",
    "                        if entity in ['%'] or word == u'$ ':\n",
    "                            word = word[:-1] + entity + u' '\n",
    "                        else:\n",
    "                            word = word + entity + u' '\n",
    "        if word != u'':\n",
    "            result_sentence.append((word[:-1],perv_type))\n",
    "        result_sentences.append(result_sentence)      \n",
    "    return result_sentences\n",
    "\n",
    "def parse_NER(ner_sentences):\n",
    "    pattern_number = re.compile(r'([0-9]+|\\%|\\$)')\n",
    "    year_number = re.compile(r'([0-9]{4}s?)')\n",
    "    result_sentences = []\n",
    "    for ner_sentence in ner_sentences:\n",
    "        result_sentence = []\n",
    "        for index,(entity,etype) in enumerate(ner_sentence):\n",
    "            if entity != u'':\n",
    "                entity.replace(u'\\u2013',u'-')\n",
    "                entity.replace(u'\\u2014',u'-')\n",
    "                entity.replace(u'\\u2212',u'-')\n",
    "                entity.replace(u'\\u2044',u'%')\n",
    "                if etype == u'O':\n",
    "                    if year_number.search(entity):\n",
    "                        result_sentence.append((entity,u'YEAR'))\n",
    "                    elif pattern_number.search(entity) or entity in time_word:\n",
    "                        result_sentence.append((entity,u'NUMBER'))\n",
    "                    elif u'-' in entity:\n",
    "                        word_seperate = entity.split(u'-')\n",
    "                        for word in word_seperate:\n",
    "                            if word in time_word:\n",
    "                                result_sentence.append((entity,u'NUMBER'))\n",
    "                                break\n",
    "                    elif entity in location_word:\n",
    "                        result_sentence.append((entity,u'LOCATION'))\n",
    "                    elif index == 0 and entity.lower() not in stopwords:\n",
    "                        result_sentence.append((entity,u'ORGANIZATION'))\n",
    "                    elif index != 0 and entity[0].isupper():\n",
    "                        result_sentence.append((entity,u'ORGANIZATION'))\n",
    "                    else:\n",
    "                        result_sentence.append((entity,etype))\n",
    "                elif entity in ['(',')']:\n",
    "                    result_sentence.append((entity,u'O'))\n",
    "                else:\n",
    "                    result_sentence.append((entity,etype))\n",
    "        result_sentences.append(result_sentence)\n",
    "        \n",
    "    return result_sentences\n",
    "\n",
    "def extract_NER(parse_ner_sentence,mode):\n",
    "    result = []\n",
    "    if mode == 0:\n",
    "        #PERSON\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'PERSON':\n",
    "                result.append(entity)\n",
    "    elif mode == 1:\n",
    "        #NUMBER\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'NUMBER':\n",
    "                result.append(entity)\n",
    "    elif mode == 2:\n",
    "        #LOCATION\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'LOCATION':\n",
    "                result.append(entity)\n",
    "    elif mode == 3:\n",
    "        #ORGANIZATION\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'ORGANIZATION':\n",
    "                result.append(entity)\n",
    "    elif mode == 4:\n",
    "        #YEAR\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'YEAR':\n",
    "                result.append(entity)\n",
    "    return result\n",
    "\n",
    "def parse_token(token_sentence):\n",
    "    result = []\n",
    "    for index,word in enumerate(token_sentence):\n",
    "        if index != 0 and index != (len(token_sentence)-1) and word == u'.':\n",
    "            last_word = result[-1]\n",
    "            last_word = last_word + u'.'\n",
    "            result = result[:-1]\n",
    "            result.append(last_word)\n",
    "        else:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Only consider queries with 'What'/'what'\n",
    "def getHeadWord(text):\n",
    "    text = text.encode('ascii','replace')\n",
    "    pos =  pos_tag(word_tokenize(text))\n",
    "    if pos[0]==('Which', 'JJ'):\n",
    "        pos[0] = ('Which', 'WHICH')\n",
    "    for i,item in enumerate(pos):   \n",
    "        #print ('item',item)\n",
    "        word = item[0].lower()\n",
    "        ppos = item[1]\n",
    "        if word=='what' and (ppos=='WP' or ppos=='WDT'):\n",
    "            pos[i] = ('what', 'WHAT')   \n",
    "        elif word=='which' and ppos=='JJ':\n",
    "            pos[i] = ('which', 'WHICH')  \n",
    "    #print pos\n",
    "    grammar = r\"\"\"\n",
    "                V: {<V.*>}          # Verb\n",
    "                HEAD:\n",
    "                    {<IN>?<WHAT><V>?<DT>?<JJ.*|CD>*<V>?<IN>?<NN.*>+}\n",
    "                    {<IN>?<WHAT><V>?<DT>?<JJ.*|CD>*<V>?<IN>?<VBG.*>+}\n",
    "                    }<IN>?<WHAT><V>?<DT>?<JJ.*|CD>*<V>?<IN>?{  \n",
    "                \"\"\"\n",
    "    cp = nltk.RegexpParser(grammar) \n",
    "    result = []\n",
    "    tree = cp.parse(pos)\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label()=='HEAD':\n",
    "            phrase = u' '.join([word for word,pos in subtree.leaves()])\n",
    "            phrase_list = phrase.split()\n",
    "            if len(phrase_list)>1:\n",
    "                ph = phrase_list[-1]\n",
    "            else:\n",
    "                ph = phrase\n",
    "            result.append(ph)\n",
    "            #print subtree.label()+':'+phrase+'->'+ph       \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "headwords = []\n",
    "year_pattern = re.compile(r'(^[0-9]{4}s?$)')\n",
    "person_pattern = re.compile(r'(^(the )?([A-Z]+[a-zA-Z\\']+ ?((&|and|of) )?)+$)')\n",
    "number_pattern = re.compile(r'([0-9]+)')\n",
    "the_pattern = re.compile(r'(^the)')\n",
    "\n",
    "year_headword = {}\n",
    "organization_headword = {}\n",
    "person_headword = {}\n",
    "number_headword = {}\n",
    "location_headword = {}\n",
    "\n",
    "for article in train:\n",
    "    qas = article['qa']\n",
    "    sentences = article['sentences']\n",
    "    token_sentences = copy.deepcopy(sentences)\n",
    "    for i in range(len(sentences)):\n",
    "        token_sentences[i] = nltk.word_tokenize(token_sentences[i])\n",
    "    ner_sentences = st.tag_sents(token_sentences)\n",
    "    parse_ner_sentences = parse_NER(ner_sentences)\n",
    "    #print parse_ner_sentences\n",
    "    for qa in qas:\n",
    "        rank = {}\n",
    "        ner_sentence = parse_ner_sentences[qa['answer_sentence']]\n",
    "        for word in nltk.word_tokenize(qa['answer']):\n",
    "            for w,t in ner_sentence:\n",
    "                if t != u'O' and w == word:\n",
    "                    rank[t] = rank.get(t,0) + 1\n",
    "        result = sorted(rank.items(), lambda x, y: cmp(x[1], y[1]), reverse=True)\n",
    "        if result != []:        \n",
    "            kind = result[0][0]\n",
    "            text = qa['question']\n",
    "            if kind == u'NUMBER':\n",
    "                for word in getHeadWord(text):\n",
    "                    number_headword[word] = number_headword.get(word,0) + 1\n",
    "            elif kind == u'YEAR':\n",
    "                for word in getHeadWord(text):\n",
    "                    year_headword[word] = year_headword.get(word,0) + 1\n",
    "            elif kind == u'ORGANIZATION':\n",
    "                for word in getHeadWord(text):\n",
    "                    organization_headword[word] = organization_headword.get(word,0) + 1\n",
    "            elif kind == u'PERSON':\n",
    "                for word in getHeadWord(text):\n",
    "                    person_headword[word] = person_headword.get(word,0) + 1\n",
    "            elif kind == u'LOCATION':\n",
    "                for word in getHeadWord(text):\n",
    "                    location_headword[word] = location_headword.get(word,0) + 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  [u'protests', u'frame', u'constellations', u'years', u'born', u'election', u'year', u'yer', u'decade', u'span', u'Bowers', u'rains', u'frog', u'crime', u'window', u'Bower', u'America', u'decades', u'preseason', u'attention', u'Dewar', u'Microsoft', u'require', u'Period', u'influx', u'periods']\n",
      "Organ:  [u'writings', u'AGG', u'Jayapala', u'dynasty', u'protest', u'Lodge', u'NYC', u'relationships', u'Foundation', u'patches', u'invaders', u'investigation', u'sub-group', u'teaching', u'League', u'risk', u'Industry', u'rise', u'slaveholder', u'pigment', u'GE', u'Digimon', u'Henry', u'look', u'school', u'prize', u'SNL', u'someplaces', u'samurai', u'debris', u'footrace', u'IXs', u'Occitan', u'Jing', u'Bavaria', u'force', u'leaders', u'Strasbourg', u'Festival', u'Mizrach', u'nail', u'follow', u'monster', u'employ', u'organisms', u'offshoots', u'commemorating', u'orchestra', u'sung', u'SAGW', u'fossil', u'churches', u'Amphetamine', u'admiral', u'VLW', u'evolutionism', u'Neptune', u'Branch', u'men', u'affiliates', u'conglomerate', u'protection', u'studio', u'codecs', u'cult', u'aftermath', u'Marshal', u'celebration', u'Leagues', u'property', u'forum', u'items', u'study', u'Queen', u'Jewels', u'controversy', u'credit', u'DETEC', u'military', u'mistake', u'changes', u'vinyl', u'Group', u'Jew', u'campaign', u'Galschi', u'lodges', u'feelings', u'VBR', u'Sputnik', u'guests', u'prokaryotes', u'unit', u'plot', u'spoke', u'army', u'hospital', u'June', u'symphony', u'music', u'Hokkien', u'type', u'alphabet', u'relay', u'Ministry', u'wars', u'award', u'warn', u'Kolotnytska', u'championships', u'adult', u'Gould', u'V', u'Chinook', u'squad', u'circumstances', u'decoration', u'word', u'room', u'rights', u'work', u'movies', u'era', u'Lund', u'exceptions', u'ORE', u'Convulsion', u'example', u'inscription', u'give', u'Corporation', u'climax', u'currency', u'foods', u'kingdoms', u'want', u'Lord', u'times', u'ceremony', u'LE', u'end', u'thing', u'provide', u'travel', u'Massacre', u'feature', u'revisit', u'machine', u'Muslims', u'Jordan', u'III', u'dialect', u'BYU', u'minority', u'railways', u'lag', u'Castro', u'law', u'arch', u'types', u'pantheism', u'occurence', u'Civil', u'Serbia', u'Rulers', u'complexity', u'things', u'atrocity', u'Beyonc', u'order', u'wind', u'Brazil', u'Belorussians', u'interpretation', u'office', u'reforms', u'Famicom', u'AAAD', u'mystics', u'reformers', u'Catholics', u'Abbott', u'SAC', u'interaction', u'SEATO', u'A-device', u'Xerox', u'writing', u'production', u'strand', u'Path', u'Droysen', u'SAW', u'damages', u'Judaism', u'diseases', u'Pfizer', u'OSTIA', u'band', u'schools', u'tourism', u'codename', u'bank', u'meat', u'India', u'slavery', u'grows', u'choir', u'Program', u'affiliate', u'victory', u'Black', u'Brickhouse', u'side', u'mean', u'Destiny', u'series', u'crimes', u'Hodge', u'cathedral', u'network', u'forts', u'god', u'charite', u'cameras', u'sand', u'content', u'fellowship', u'laid', u'vector', u'millennium', u'millions', u'Napoleon', u'foundation', u'University', u'Nepalese', u'standard', u'chanson', u'struggle', u'Izvestiya', u'September', u'professions', u'days', u'terriroty', u'antecedents', u'SCMS', u'Raleigh', u'Universities', u'Zedong', u'features', u'attractions', u'NARTH', u'charter', u'EchoStar', u'Buddhism', u'antibiotic', u'ECB', u'Congress', u'Academy', u'Catalan', u'master', u'Cer', u'Nintendo', u'Press', u'gowns', u'farming', u'Maeser', u'B', u'emblem', u'collapse', u'tool', u'villages', u'BBC', u'western', u'Catalans', u'Butera', u'target', u'tavern', u'tree', u'scenes', u'project', u'invention', u'Usher', u'Madonna', u'seminary', u'Offensive', u'Civitas', u'return', u'al-Shifa', u'seed', u'manner', u'bardo', u'Depot', u'seek', u'tells', u'Williams', u'strength', u'realm', u'SBVT', u'Schauspielhaus', u'DARPA', u'Albert', u'academia', u'forces', u'Brendan', u'effectiveness', u'Bank', u'citizens', u'impurities', u'theatres', u'VSDs', u'defence', u'letter', u'phase', u'coin', u'Tbilisi', u'episode', u'metal', u'dog', u'treaty', u'points', u'principle', u'enterprise', u'confederation', u'reserve', u'incorporate', u'cooking', u'bomb', u'exemption', u'jurisdiction', u'religions', u'colors', u'radio', u'CBNRM', u'guilds', u'analogue', u'layout', u'OpenType', u'situations', u'mens', u'theme', u'colonists', u'cuisines', u'lodge', u'announce', u'scripture', u'edict', u'do', u'exports', u'mixture', u'glaciers', u'Carnival', u'ultimatum', u'report', u'Organization', u'KF', u'CCM', u'Manchus', u'fields', u'humanism', u'guns', u'architecture', u'adherence', u'OAS', u'squadron', u'explanations', u'inns', u'disaster', u'reference', u'peripheral', u'zones', u'result', u'SHAEF', u'subject', u'I-94', u'Malinche', u'capacity', u'causeway', u'injuries', u'targets', u'pets', u'semiconductor', u'approach', u'K', u'discovery', u'preserve', u'C', u'admirers', u'terms', u'Nasser', u'vitamin', u'wear', u'extent', u'headline', u'Bronx', u'motto', u'kitchen', u'accident', u'facet', u'games', u'Navy', u'distinction', u'federalism', u'argue', u'negotiation', u'cemetery', u'Doordarshan', u'Upanishads', u'initiative', u'stupa', u'Carlos', u'Movement', u'conference', u'targeting', u'basis', u'union', u'Boccaccio', u'G.B', u'commission', u'beer', u'communion', u'website', u'Nasserist', u'families', u'drugs', u'suppress', u'CD', u'generals', u'child', u'Holmes', u'exception', u'Cypriot', u'formalization', u'stubs', u'transformation', u'aim', u'Delany', u'murders', u'employees', u'natives', u'NCQLP', u'Porfiriato', u'U+UFFE', u'Liberals', u'madonna', u'mouse', u'id', u'Cramer', u'descent', u'patent', u'parish', u'make', u'rebellion', u'drawback', u'split', u'Kupka', u'stuntman', u'colonies', u'Eisenhower', u'evolve', u'governors', u'qualifications', u'Ford', u'Raytheon', u'Spectre', u'pubs', u'logograms', u'characters', u'wives', u'District', u'anarchists', u'Gates', u'programs', u'Airways', u'Wettstein', u'practices', u'claims', u'contaminants', u'philosphy', u'opinions', u'protocol', u'traditions', u'bandwidth', u'DRM', u'MTBC', u'cutlture', u'divide', u'Protestants', u'enters', u'hills', u'spread', u'board', u'prison', u'Philip', u'east', u'designate', u'D', u'bands', u'disagreement', u'schooling', u'performance', u'designers', u'specie', u'Novel', u'festivities', u'offices', u'importantance', u'security', u'Prince', u'AC', u'CCIRC', u'deal', u'people', u'HP', u'System', u'clubs', u'jupiter', u'escape', u'N.S', u'nobleman', u'despcription', u'extinction', u'Institute', u'Slovak', u'core', u'Boganda', u'genomics', u'lamps', u'confrontation', u'Emperor', u'trophy', u'Madison', u'undercroft', u'attacks', u'newspapers', u'typeface', u'MPI', u'Cnut', u'magazine', u'IHDI', u'abbreviations', u'Sauerkraut', u'facility', u'Greeks', u'profession', u'administer', u'magazines', u'Geschichte', u'doctrine', u'Nistor', u'wrap', u'intermarriage', u'parade', u'segment', u'support', u'legislation', u'gallery', u'way', u'Presley', u'NBC', u'call', u'factions', u'war', u'synthesis', u'head', u'offering', u'offer', u'peninsula', u'strike', u'solar', u'C.W', u'protobacterium', u'versions', u'Czech', u'Shrimsley', u'BRT', u'POTS', u'devices', u'maximus', u'panels', u'propaganda', u'trio', u'classic', u'tournament', u'textbook', u'evidence', u'MOCAD', u'Virgil', u'prayer', u'ship', u'liberalism', u'regime', u'marking', u'upheaval', u'EAL', u'Tibet', u'glacier', u'reality', u'role', u'digital', u'test', u'dynasties', u'picture', u'TRON', u'Windows', u'Sarton', u'Melbourne', u'FORTRAN', u'authorities', u\"'n\", u'reorganization', u'Charles', u'reasoning', u'flag', u'Second', u'push', u'banners', u'consideres', u'Cristina', u'songs', u'lab', u'concept', u'chain', u'dance', u'Indians', u'alternatives', u'focus', u'Munday', u'NADGE', u'theaters', u'Republic', u'battle', u'layers', u'Bannermen', u'grape', u'technique', u'environment', u'charge', u'Danelaw', u'SHORAD', u'division', u'Suchet', u'Prize', u'advantage', u'Conkling', u'join', u'governments', u'Apollo', u'Protocol', u'EFTA', u'die', u'standards', u'item', u'team', u'Melungeon', u'shoe', u'revolution', u'thinkers', u'occurrence', u'findings', u'discover', u'sign', u'affiliation', u'Chopin', u'port', u'NESA', u'assistance', u'shares', u'uniform', u'incidents', u'reply', u'Categories', u'Mistwalker', u'Oktoberfest', u'Hopkins', u'Age', u\"'Treatise\", u'understanding', u'Feynman', u'communism', u'companies', u'groups', u'English', u'change', u'Dean', u'Portugal', u'Grotto', u'institute', u'NMEs', u'MI', u'Choskunskyabs', u'exploitation', u'trial', u'convoys', u'Hitler', u'Command', u'I-696', u'OKL', u'Gram', u'DOD', u\"d'Schwiiz\", u'crisis', u'market', u'additive', u'August', u'incantations', u'visit', u'sports', u'connector', u'territories', u'wood', u'societies', u'criteria', u'films', u'Cities', u'monumuents', u'today', u'chapter', u'galleries', u'Gigantomachy', u'reworking', u'club', u'methodist', u'curriculum', u'Indy', u'Pitt', u'downtown', u'Dharma', u'hegemoney', u'officeholder', u'Hayek', u'cases', u'effort', u'Translation', u'mascot', u'organizations', u'migrants', u'slogan', u'car', u'Pacific', u'cat', u'districts', u'values', u'DCSnet', u'dispute', u'claim', u'performer', u'downfall', u'agent', u'topic', u'critic', u'council', u'Dutch', u'hydrogen', u'Hume', u'inheritance', u'Coke', u'Austria', u'species', u'chemical', u'Tolan', u'pure', u'assistant', u'DNT', u'encampment', u'armies', u'product', u'explorer', u'critics', u'accessory', u'applications', u'membership', u'produce', u'Boudhanath', u'Martin', u'data', u'efforts', u'processors', u'H.264', u'branches', u'varieties', u'Pillsbury', u'carriers', u'NCT', u'tale', u'inhabitants', u'forebears', u'representation', u'shoes', u'UNFPA', u'constituents', u'hunting-gathering', u'professors', u'course', u'lyric', u'Abyssinia', u'westerners', u'birds', u'Mandela', u'tore', u'group', u'Zhou', u'Rules', u'organisation', u'Selim', u'forms', u'platform', u'broadcasts', u'policy', u'loophole', u'priesthood', u'coincidental', u'Atkins', u'views', u'Scotland', u'origination', u'introduce', u'records', u'Rome', u'conquer', u'HRF', u'provision', u'developments', u'possess', u'SACU', u'term', u'name', u'opera', u'settings', u'proteins', u'WISP', u'Himachal', u'heresies', u'domain', u'Television', u'conventions', u'manifesto', u'samurais', u'Suzuki', u'description', u'album', u'Ken', u'Spielberg', u'Jos', u'Elizabeth', u'factors', u'profit', u'activities', u'NES', u'priest', u'Assoc', u'UGR', u'shows', u'theory', u'siege', u'cars', u'Record', u'Stand', u'Mauri', u'keyboards', u'language', u'fundraise', u'transition', u'programming', u'Amphitheater', u'initiate', u'DDoS', u'plane', u'place', u'nonprofit', u'think', u'origin', u'cheese', u'clause', u'ISP', u'Frijda', u'IST', u'ISO', u'periodical', u'mountings', u'vote', u'sounds', u'Sapere', u'artworks', u'boulevard', u'breed', u'plastic', u'Levi', u'draft', u'Galicia', u'Laing', u'inadmissability', u'reappropriation', u'SASO', u'festivity', u'Rajasthans', u'Fortune', u'appointees', u'heritage', u'CFL', u'artifact', u'expanse', u'broadcast', u'canine', u'Torrio', u'stle', u'television', u'Amer', u'rival', u'officials', u'fruits', u'tribesman', u'outcome', u'oath', u'browser', u'gathering', u'illness', u'DJ', u'topics', u'Prussia', u'locations', u'departure', u'say', u'Down', u'speakers', u'form', u'transcription', u'Avicenna', u'Beaks', u'equipment', u'emphasis', u'potential', u'Hale', u'take', u'objective', u'BTSR', u'sultanate', u'Hall', u'channel', u'Articles', u'begin', u'pain', u'theatre', u'opposite', u'track', u'enter', u'Constantine', u'sheets', u'Predictor', u'Portuguese', u'Truman', u'failure', u'adopt', u'Philadelphia', u'wing', u'Turko-Mongol', u'slaves', u'Psalm', u'laws', u'shop', u'lexicon', u'systmes', u'Babangida', u'show', u'sites', u'Renaixenca', u'Barre', u'inhibitors', u'Roll', u'boundaries', u'title', u'proclamation', u'storms', u'pump', u'RIM', u'chopin', u'stain', u'NTB', u'interstate', u'Jhanas', u'moons', u'TTYs', u'outlet', u'singer-songwriter', u'dye', u'conjunction', u'boundary', u'celebrate', u'Lantern', u'Alliance', u'resource', u'consist', u'precdence', u'Uruguay', u'USAAC', u'city-state', u'bombs', u'Forces', u'Grant', u'inquiry', u'stipulation', u'subgenres', u'college', u'Claris', u'Musharraf', u'Armory', u'calendar', u'sport', u'concern', u'ways', u'diode', u'representatives', u'label', u'LDS', u'Berlin', u'skyscraper', u'Bredow', u'import', u'Ummah', u'conferencing', u'Palace', u'Bible', u'U.S.', u'supermarket', u'killing', u'OSHA', u'nationality', u'reaction', u'dates', u'residence', u'termed', u'job', u'tour', u'patrons', u'Unicode', u'designations', u'Laboratory', u'railway', u'concert', u'datings', u'color', u'period', u'Multics', u'article', u'Metzingers', u'Leader', u'amino', u'Cobden', u'west', u'mark', u'Schools', u'prototype', u'Princess', u'laptops', u'observe', u'stalemate', u'champions', u'sharpshooters', u'case', u'Marshall', u'associates', u'UNTAG', u'policies', u'newspaper', u'situation', u'constituency', u'trader', u'operate', u'polymer', u'conferences', u'SFOE', u'Epistle', u'DIA', u'dedicate', u'converts', u'Somali', u'somebody', u'protein', u'technology', u'movements', u'bags', u'Israel', u'revolutions', u'Midna', u'media', u'Freddie', u'food', u'Matorell', u'speech', u'deference', u'figures', u'XXI', u'document', u'events', u'status', u'predator', u'II', u'formats', u'advertisement', u'paradox', u'IC', u'IRC', u'tradition', u'atkins', u\"O'Neill\", u'theater', u'Arius', u'charges', u'components', u'model', u'modem', u'interface', u'dimension', u'researchers', u'scholarship', u'NAB', u'Sharia', u'battleship', u'rest', u'BOM', u'aspect', u'death', u'co-found', u'Duchy', u'brogue', u'instrument', u'verse', u'treatment', u'thoughts', u'republic', u'careers', u'styles', u'boast', u'rules', u'Dorgon', u'Project', u'inflation', u'preference', u'vacuum', u'symbolism', u'world', u'Scherbytsky', u'fortune', u'ASEAN', u'Contemporary', u'Augustus', u'benefit', u'retailers', u'friar', u'tower', u'grouping', u'Army', u'West', u'Punjab', u'draw', u'competition', u'CSAD', u'manufacturers', u'service', u'duration', u'Mary', u'Afro-Spaniards', u'brothers', u'DBMS', u'teachings', u'mercenaries', u'decomposition', u'provider', u'ethos', u'refer', u'UNSCOP', u'business', u'LoC', u'equivalent', u'Vietnam', u'Forsyth', u'Duveger', u'Earp', u'manufacturer', u'comparison', u'Revolution', u'origins', u'stations', u'Transit', u'fringe', u'insect', u'ideology', u'flatworms', u'wolf', u'airline', u'act', u'processor', u'organizers', u'tribe', u'No', u'communication', u'Bowl', u'Arkansas', u'determine', u'parties', u'operator', u'paganism', u'telescope', u'NBCSN', u'Aeneas', u'EMALS', u'start', u'cats', u'cultures', u'energy', u'BSAR-1', u'ELF', u'Treaty', u'philosophers', u'Steuben', u'hurricanes', u'promote', u'LED', u'House', u'interiors', u'polity', u'FBI', u'beliefs', u'patois', u'VISP', u'USB', u'viruses', u'migrate', u'describe', u'Cemetery', u'Airlines', u'lichen', u'file', u'Ehrenstein', u'politics', u'dignitaries', u'film', u'Monica', u'genres', u'strikers', u'moniker', u'KUOW', u'hybrid', u'smartphones', u'field', u'Watson', u'PCEEO', u'Chronicle', u'students', u'symbol', u'finale', u'Nations', u'Empire', u'ClarisWorks', u'building', u'observers', u'subdivision', u'assets', u'odds', u'Spinoza', u'precedent', u'derrick', u'dialects', u'represent', u'colleges', u'consider', u'declaration', u'dollar', u'spacecraft', u'Station', u'Fid', u'dish', u'Wickers', u'meditation', u'children', u'causes', u'carpet', u'Brown', u'hunting', u'homage', u'removal', u'NCAZ', u'prophets', u'program', u'heterogeneity', u'Christians', u'sound', u'appointment', u'speaches', u'song', u'Dante', u'Raeder', u'A17.1', u'decide', u'fall', u'difference', u'condition', u'adjective', u'NPO', u'dictatorship', u'list', u'dinosaur', u'Jiguang', u'Claridge', u'ASCII', u'titles', u'design', u'perspective', u'pass', u'East', u'Helios', u'Latin', u'Jaipal', u'section', u'CPU', u'version', u'AlGaN', u'tribute', u'foot-race', u'method', u'movement', u'idealism', u'Russians', u'component', u'combating', u'Constable', u'Archer', u'deaths', u'fuly', u'co-language', u'arena', u'publisher', u'Jews', u'Clark', u'difficulty', u'outgrowth', u'Sega', u'deities', u'experience', u'philosophies', u'masterpiece', u'emulator', u'action', u'mentions', u'specialize', u'options', u'Gaddafi', u'family', u'deals', u'Richmond', u'texts', u'Standard', u'REF', u'teritory', u'Europe', u'FCS', u'Explorer', u'warship', u'objectives', u'destination', u'Cork', u'Romans', u'Picasso', u'markets', u'ballad', u'loanwords', u'Intel', u'deism', u'hunter-gatherers', u'company', u'emission', u'Factory', u'American', u'Pegasys', u'known', u'Dell', u'objections', u'Desfile', u'Programme', u'debates', u'science', u'Fr', u'learn', u'Cathedral', u'Andrade', u'history', u'civilizations', u'IBM', u'Enneads', u'Legion', u'epics', u'accept', u'protects', u'phrase', u'airplane', u'CAF', u'salts', u'Basset', u'information', u'Parliament', u'court', u'goal', u'plans', u'influences', u'reject', u'Koreans', u'ASIS', u'plant', u'circuit', u'countryside', u'uprising', u'fungus', u'tries', u'missiles', u'lighting', u'invasion', u'response', u'geneologists', u'cults', u'short', u'resemble', u'racetrack', u'responsibility', u'sect', u'Hebrew', u'banks', u'Kuomintang', u'Raskin', u'help', u'mission', u'trade', u'paper', u'committee', u'avenue', u'Trinity', u'developer', u'Korshel', u'style', u'TDM', u'Berners-Lee', u'epoch', u'abbey', u'urbanization', u'resort', u'systems', u'Hamburg', u'followers', u'fines', u'colleague', u'IALD', u'I-19', u'URL', u'propose', u'L', u'sownturn', u'framework', u'Era', u'Bolshevik', u'compound', u'communities', u'Mogadishu', u'association', u'Amendment', u'juncture', u'IPA', u'designation', u'hails', u'occasions', u'Newton', u'capability', u'Council', u'resurface', u'monsoon', u'constructing', u'Kabbalah', u'magi', u'house', u'Specification', u'Indvuna', u'idea', u'connect', u'operation', u'McCarthy', u'event', u'Nizamiyah', u'initiatives', u'flower', u'lable', u'research', u'villians', u'issue', u'highway', u'CGLI', u'Ukraine', u'patriation', u'disobedience', u'belief', u'NOFORN', u'pub', u'side-effects', u'houses', u'reason', u'coastline', u'members', u'EU', u'attendant', u'Lavrov', u'definition', u'benefits', u'revival', u'launch', u'metamorphosis', u'computers', u'conglomeration', u'Phoenicans', u'NASA', u'threat', u'pilots', u'Cyril', u'statue', u'encoding', u'feel', u'consideration', u'Oklahoma', u'Mennonites', u'temples', u'story', u'landmass', u'heads', u'Dictionary', u'script', u'A38', u'scholars', u'station', u'mosaic', u'Everton', u'scheme', u'aristocracy', u'store', u'STOIC', u'option', u'relationship', u'park', u'Meyerson', u'cartridges', u'norms', u'translation', u'XV', u'kind', u'homophones', u'Kramer', u'organiztion', u'Quranic', u'ISPs', u'subsidise', u'Operation', u'Pike', u'God', u'ages', u'juice', u'airstrike', u'ratings', u'nights', u'Triangle', u'Club', u'Virginia', u'bacteria', u'majority', u'build', u'Freemasonry', u'Spirit', u'Germans', u'Durga', u'towards', u'James', u'singles', u'eggs', u'chart', u'promenade', u'virus', u'plan', u'Gromyko', u'services', u'prophecy', u'achievement', u'Google', u'Scudamore', u'sun-god', u'cover', u'Nanjing', u'storyline', u'bodies', u'Speed', u'institutions', u'joining', u'sector', u'rebels', u'obligations', u'commissions', u'memorandum', u'spirochete', u'session', u'Twelvers', u'Hinkley', u'Ismailis', u'heavens', u'networks', u'occupation', u'Kingdom', u'giant', u'Glastonbury', u'merger', u'Muslim', u'assertion', u'enzyme', u'factor', u'poles', u'founding', u'permission', u'referees', u'Somalias', u'trees', u'immunoassays', u'actions', u'Randall', u'banner', u'cry', u'Sunday', u'bird', u'activity', u'endeavor', u'Incursion', u'restaurants', u'Whitehead', u'art', u'intelligence', u'France', u'culture', u'individual', u'migration', u'close', u'arm', u'locals', u'Morrison', u'stance', u'Song', u'movie', u'Blair', u'libraries', u'fans', u'laguages', u'Light', u'flame', u'viewership', u'conditions', u'DST', u'compliment', u'King', u'Mahayana', u'GRTC', u'embargoes', u'Florida', u'denomination', u'Goldstone', u'aircraft', u'opposition', u'genre', u'Duisenberg', u'legislature', u'league', u'license', u'influential', u'minorities', u'connection', u'context', u'goverment', u'vault', u'Graham', u'phylogenetics', u'FLAC', u'reasons', u'address', u'corresponds', u'pamphlet', u'GRECO', u'adaptation', u'church', u'vessel', u'desktop', u'Cobh', u'War', u'complication', u'Macs', u'duo', u'Students', u'create', u'acceptance', u'strategy', u'B.I.C', u'reduction', u'Senora', u'armory', u'Anusim', u'meeting', u'firm', u'Allies', u'girls', u'Corinth', u'Athanasius', u'races', u'representative', u'demand', u'domination', u'towns', u'Michel', u'plants', u'Old', u'Chinese', u'Classification', u'bill', u'elections', u'College', u'Church', u'fleet', u'guide', u'Shannon', u'City', u'LEDs', u'Italy', u'voters', u'orthography', u'Semiconductor', u'rulers', u'obstacle', u'audiobooks', u'ethnicity', u'RCC', u'cuisine', u'belong', u'ideologies', u'Nation', u'corridor', u'peoples', u'modification', u'Copy', u'conflict', u'development', u'Trubetzkoy', u'epithet', u'alert', u'Movies', u'uses', u'purpose', u'implementation', u'cityscape', u'UCS', u'nickname', u'fabrication', u'scriptures', u'studies', u'analysis', u'person', u'edge', u'consistency', u'landmark', u'organization', u'Staff', u'coup', u'Maysum', u'telegram', u'abbreviation', u'shape', u'CCI', u'reviewer', u'alternative', u'discipline', u'cup', u'workers', u'Divergence', u'signals', u'source', u'subjects', u'Hindu', u'app', u'Orthagraphy', u'associations', u'march', u'format', u'subfield', u'advocate', u'Air', u'game', u'Abbey', u'emergence', u'confraternity', u'projects', u'Op', u'commandery', u'back-transliteration', u'polymers', u'bgean', u'individuals', u'translators', u'Berggarten', u'OS', u'methods', u'collectors', u'senate', u'creation', u'streamers', u'examples', u'festivals', u'Burke', u'Dame', u'denominations', u'Guofan', u'vocalizations', u'decision', u'Tufail', u'religion', u'civilization', u'Familial', u'dating', u'Boy', u'GBAD', u'agreement', u'colonization', u'step', u'William', u'Policies', u'Davis', u'Russia', u'vaccine', u'Pack', u'faith', u'Basilica', u'consumption', u'PCBs', u'violins', u'plaza', u'equivilent', u'beans', u'Ottoman', u'replacement', u'block', u'Kwajalein', u'microorganism', u'ACE', u'roots', u'Patrick', u'retailer', u'NEC', u'Hawking', u'contributor', u'millet', u'question', u'pronunciation', u'Yaroslav', u'Unification', u'Sun', u'certification', u'translate', u'sections', u'Tibetans', u'Fe', u'Declaration', u'Holocaust', u'boys', u'link', u'delta', u'Switzerland', u'subsidiary', u'line', u'Resolution', u'ceremonies', u'microorganisms', u'Office', u'Bell', u'licensees', u'iMac', u'planet', u'Egypt', u'Parnell', u'Westerners', u'export', u'groove', u'bell', u'geese', u'Neurath', u'expedition', u'influence', u'images', u'October', u'COMESA', u'home', u'Singh', u'Mas', u'encoders', u'May', u'uranium', u'Opera', u'Mac', u'TM', u'functionality', u'genome', u'department', u'Mises', u'revision', u'sutra', u'spectators', u'beginnings', u'problems', u'regulations', u'meaning', u'CAP', u'desert', u'structure', u'Taft', u'organism', u'youtube', u'departments', u'hapend', u'beverage', u'wording', u'Mercury', u'code', u'Beyonce', u'results', u'Department', u'MANPADS', u'issues', u'Revision', u'send', u'languages', u'suite', u'charity', u'Arroyo', u'ingredient', u'Agency', u'Holland', u'wave', u'P', u'artery', u'categories', u'premise', u'Kyi', u'treaties', u'positions', u'button', u'try', u'race', u'verdict', u'gauge', u'Seattle', u'Tamuramaro', u'PLDA', u'wrestling', u'scientist', u'demonstrations', u'video', u'Beckford', u'licenses', u'assembly', u'Somerset', u'makers', u'universities', u'index', u'font', u'power', u'directive', u'showcase', u'schedule', u'Link', u'sub-signals', u'Tibetan', u'constitutency', u'body', u'impact', u'dub', u'degree', u'exchange', u'CCTV', u'indicator', u'Greek', u'separation', u'IGO', u'sing', u'McKenna', u'IMAP', u'Boyer', u'Technicolor', u'CBC', u'microbrewery', u'biodiversity', u'algorithim', u'receive', u'chant', u'overseen', u'contradiction', u'CBR', u'CBS', u'leadership', u'products', u'defeat', u'opinion', u'residents', u'gene', u'initials', u'Category', u'examinations', u'scales', u'win', u'Tito', u'Rock', u'hardy', u'FC', u'names', u'scandal', u'Veltman', u'staple', u'use', u'fee', u'certificate', u'Seagram', u'Newfoundland', u'UCCCMI', u'NATO', u'vehicle', u'Eskimo', u'sort', u'parliament', u'trait', u'Feast', u'missile', u'train', u'rivalry', u'starter', u'women', u'account', u'animals', u'Estonia', u'Khrushchev', u'Library', u'reserves', u'publications', u'SNES', u'narratives', u'SECARMY', u'industry', u'control', u'predecessor', u'process', u'pieces', u'tag', u'something', u'hit', u'caliph', u'Schwarzenegger', u'AMC', u'formations', u'arrangement', u'delay', u'responsibilities', u'winners', u'animal', u'comedy', u'establishment', u'stand', u'profile', u'buildings', u'blocks', u'VOR', u'Philo', u'philosophy', u'Stirling', u'collection', u'SPECTRE', u'Roman', u'tier', u'Gyaltsen', u'Sadat', u'Apple', u'lines', u'Community', u'element', u'bakery', u'encyclopedia', u'allow', u'alloy', u'software', u'Crosland', u'Wilson', u'Quaker', u'emissaries', u'symbols', u'strove', u'Buddha', u'industries', u'regions', u'Shell', u'Exchange', u'AHRA', u'SVCD', u'inclusion', u'ships', u'Buffet', u'seige', u'FGM', u'choose', u'receptacles', u'holiday', u'phenomenon', u'Haven', u'Sina', u'junction', u'Ridgway', u'Rawsl', u'UNHCR', u'Miami', u'dam', u'material', u'runs', u'GNIpc', u'Nachmanides', u'USAID', u'Cao', u'satellites', u'literacy', u'Dessouki', u'hallmarks', u'Aavik', u'Friends', u'university', u'VII', u'DIANE', u'subcontinent', u'merge', u'mode', u'studios', u'Knorr', u'Stadium', u'Bonaparte', u'strip', u'Germanic', u'OCF', u'Witnesses', u'society', u'frequency', u'measure', u'bay', u'STA', u'empires', u'populace', u'Alonso', u'Ariostle', u'etymology', u'CAID', u'China', u'cause', u'ORNL', u'Stage', u'classification', u\"'war\", u'dictionary', u'recommendations', u'CSA', u'MRAP', u'ancestry', u'mainland', u'Portable', u'route', u'unity', u'Jesus', u'artifacts', u'PXFM', u'qualification', u'retain', u'Binford', u'distinguish', u'SKU', u'manuscript', u'Prussian', u'Review', u'Yale', u'Administration', u'bazaars', u'Rawls', u'improvements', u'hurdle', u'Jackson', u'Screvin', u'quality', u'publication', u'Centre', u'festival', u'Powers', u'accent', u'system', u'priority', u'attack', u'Bengel', u'decorations', u'adopter', u'neurotransmitter', u'tourists', u'Association', u'Palermo', u'Thuringia', u'academy', u'explanation', u'transistor', u'monotheism', u'R', u'Writ', u'simulate', u'elite', u'institution', u'RoHS', u'neologism', u'contoller', u'treatise', u'Wright', u'Universal', u'Djibouti', u'disband', u'sculpture', u'Macau', u'descriptions', u'behaviors', u'partnership', u'Machine', u'Gomes', u'turn', u'metaphysics', u'microphone', u'documents', u'bacterium', u'agency', u'parks', u'mix', u'relatives', u'KUSMS', u'reactions', u'Bells', u'BIS', u'vegetation', u'Hendry', u'centre', u'Games', u'Kanye', u'device', u'draws', u'medal', u'class', u'statute', u'WINEP', u'consequences', u'Muawiyah', u'disease', u'generation', u'Blvd', u'programmers', u'fact', u'ho', u'Jubilee', u'atmosphere', u'selection', u'chances', u'text', u'charles', u'MoU', u'Panentheism', u'Nakajima', u'soldiers', u'fear', u'debate', u'partners', u'RDN', u'knowledge', u'controls', u'employer', u'buttons', u'entities', u'equivalents', u'Legend', u'hope', u'move', u'means', u'midnight', u'Wycliffe', u'impeachment', u'words', u'Islands', u'entity', u'tolerance', u'taxes', u'teams', u'Broadway', u'Minden', u'view', u'FIFA', u'Synagogue', u'ECOS', u'exists', u'Traductorum', u'humans', u'packet', u'differs', u'intensity', u'computer', u'Hirsch', u'Jiadong', u'reform', u'pattern', u'PC', u'Restoration', u'July', u'DiFruscia', u'franchises', u'Kai-Shek', u'PLASA', u'ability', u'opening', u'attempt', u'monarchy', u'agencies', u'HMMWV', u'Univerity', u'historians', u'Kathmandu', u'police', u'Macintosh', u'Emotion', u'restrictions', u'Rassmann', u'ethnicities', u'RNA', u'incident', u'drug', u'admit', u'streams', u'comment', u'subtitle', u'Christ', u'wall', u'vaccines', u'Patton', u'OFUNAM', u'franchise', u'sequences', u'kings', u'mafia', u'poem', u'Sangha', u'SAMs', u'quip', u'addition', u'Monarchy', u'AAUP', u'Hornigk', u'offers', u'agreements', u'proposal', u'citation', u'Center', u'retrospective', u'angiosperm', u'SMTP', u'climate', u'sales', u'controller', u'Nacional', u'novel', u'laser', u'inn', u'General', u'Eton', u'indicaters', u'Battle', u'balance', u'mythology', u'layer', u'hardware', u'Goldwater', u'Hinduism', u'Kafur', u'education', u'Ranjha', u'landmarks', u'administration', u'cross', u'N.S.A', u'buddhism', u'MBTA', u'units', u'party', u'disc', u'Tribunal', u'practice', u'drink', u'effect', u'variance', u'sisters', u'Order', u'expand', u'destruction', u'ARP', u'Bucopho', u'center', u'VWN', u'weapon', u'contest', u'fighting', u'command', u'sets', u'position', u'stores', u'rocket', u'offensive', u'sources', u'clinic', u'voltage', u'skill', u'Avalon', u'Brigade', u'console', u'Theodosius', u'Company', u'supply', u'Gaddifi', u'discuss', u'Sarkozy', u'combine', u'citizen', u'Norbulingka', u'Beaux', u'successor', u'indignation', u'Anschluss', u'cuneiform', u'government', u'sweep', u'Biano', u'deployment', u'loss', u'England', u'success', u'dictionaries', u'Galicians', u'hosts', u'become', u'works', u'refugees', u'page', u'Alfranj', u'amendment', u'professorship', u'Ireland', u'sequence', u'elevators', u'Thunder', u'library', u'Rebellion', u'growth', u'gymnastics', u'Barts', u'kinds', u'empire', u'competitor', u'congress', u'lead', u'OSS', u'hurricane', u'mines', u'demonstrators', u'Montana', u'Federations', u'limitations', u'Rhodians', u'thoroughfare', u'reappointment', u'acronym', u'Pandeism', u'expansion', u'pressure', u'host', u'nationalities', u'Kerry', u'Seminary', u'refuge', u'stage', u'boards', u'column', u'Haganah', u'Ayer', u'dependence', u'US', u'surge', u'carrier', u'Americans', u'UK', u'Japan', u'concession', u'documentary', u'Mayor', u'UB', u'photovoltaic', u'alliance', u'letters', u'Arts', u'guard', u'weather', u'female', u'artists', u'Nakamura', u'blockhouses', u'Brunel', u'Shimla', u'transfer', u'museum', u'apps', u'November', u'function', u'dispensaries', u'interest', u'Science', u'brand', u'cantons', u'volume', u'Boehner', u'Extras', u'Harlan', u'gain', u'courts', u'anti-masonics', u'tactics', u'ecosystem', u'official', u'variations', u'BSoD', u'record', u'lingo', u'monument', u'problem', u'piece', u'display', u'Laden', u'Harbi', u'Carthage', u'crusade', u'abbot', u'ink', u'OSUT', u'SWAPO', u'campus', u'chromosome', u'variety', u'corporation', u'Islamic', u'book', u'details', u'branch', u'Lavalleja', u'Phase', u'Dvorak', u'clicks', u'conclusion', u'category', u'Pantheism', u'variation', u'enlargement', u'genus', u'Act', u'coccus', u'cajoling', u'Buddism', u'Examiner', u'Corps', u'bishop', u'Site', u'rule', u'atheism', u'FARMS', u'yell']\n",
      "Person:  [u'Neuman', u'founder', u'manager', u'Morovic', u'talks', u'chair', u'compose', u'Assemblyman', u'passage', u'painters', u'logician', u'painter', u'idealist', u'include', u'woman', u'Cid', u'KSOG', u'Topnail', u'affect', u'prefect', u'scholar', u'knight', u'Hameidi', u'villa', u'prediction', u'thinker', u'Shakespeare', u'insertion', u'cartel', u'panda', u'atman', u'captain', u'Deleuze', u'Bilal', u'crush', u'Popper', u'scientists', u'reporter', u'witch', u'legend', u'talent', u'biographies', u'shift', u'deers', u'ALS', u'reds', u'straw', u'Laemmle', u'composer', u'franca', u'algae', u'discourses', u'conquistador', u'Charity', u'musician', u'Menzies', u'dogma', u'orator', u'sculptor', u'Neumann', u'Pope', u'Yousong', u'German', u'equation', u'Politicians', u'concepts', u'meet', u'figure', u'attribute', u'instrumentalism', u'tax', u'Dominicans', u'botanist', u'monuments', u'writers', u'answer', u'Zealand', u'algebra', u'variant', u'president', u'man', u'neopragmatist', u'doctor', u'Luke', u'neglect', u'producer', u'Anatolia', u'setback', u'Xianzhong', u'Rotten', u'Jah', u'deity', u'mayor', u'Stein', u'acknowledge', u'relativity', u'degrees', u'ally', u'Dominican', u'descendants', u'mention', u'President', u'front', u'Friar', u'Dominic', u'investor', u'sects', u'investiture', u'mathematician', u'identifier', u'Martel', u'decree', u'novels', u'health', u'strategist', u'brewery', u'Theater', u'ofen', u'grapes', u'explorers', u'ex-speaker', u'congressman', u'musicians', u'castle', u'copper', u'Rastrakuta', u'student', u'researcher', u'waves', u'Historian', u'Asia', u'navigator', u'engineer', u'top', u'historian', u'teacher', u'saint', u'convention', u'friend', u'subplot', u'reinforcements', u'Mozart', u'expatriate', u'believe', u'Nobunaga', u'Lenin', u'performers', u'recording', u'Kaunitz', u'architect', u'feeling', u'symmetries', u'makhtesh', u'Meinhard', u'philosphers', u'ballerina', u'warriors', u'Minister', u'doors', u'play', u'transactions', u'rappers', u'frontman', u'pharaoh', u'architects', u'rehearsal', u'Priest', u'rationale', u'icon', u'Bridge', u'singer', u'seize', u'conquests', u'professor', u'velocity', u'physics', u'scream', u'detective', u'pope', u'authors', u'contemporary', u'traitor', u'industrialist', u'economist', u'Powell', u'principal', u'archbisoph', u'justice', u'writer', u'French', u'employee', u'meant', u'Rommel', u'executive', u'king', u'artist', u'rapper', u'extremists', u'husband', u'grain', u'Toppman', u'locale', u'Archbishop', u'AEA', u'see', u'churchman', u'Babylon', u'expert', u'Noriega', u'Tillcar', u'Gautama', u'Rajasthanis', u'importance', u'physiologist', u'Bronn', u'monk', u'officer', u'Tipitaka', u'mausoleum', u'J.C.B', u'knee-deep', u'Elizabethan', u'discoverer', u'Kermes', u'biographer', u'zinc', u'Hamilton', u'Scout', u'poet', u'Singer', u'Adams', u'Georgie', u'present', u'politician', u'Deputy', u'governor', u'monumnet', u'aid', u'Spiro', u'resident', u\"O'Daniel\", u'commander', u'player', u'Bush', u'arenas', u'Admiral', u'synagogue', u'author', u'sociologist', u'member', u'negotiations', u'monarch', u'inventors', u'functions', u'director', u'senator', u'Polya', u'No.46', u'bearer', u'settlements', u'actress', u'prince', u'Bahrain', u'candidate', u'photographer', u'character', u'advancement', u'collections', u'usage', u'humanity', u'match', u'chairman', u'complaint', u'fate', u'Restaurant', u'ruler', u'royalty', u'judge', u'clan', u'Jehovah', u'Creed', u'broadcaster', u'journalist', u'prosector', u'sketch', u'composers', u'Lee', u'philosopher', u'Oberhauser', u'Sulla', u'commentator', u'leader', u'biopic', u'Stengers', u'refers', u'beaches', u'Gelug', u'sister', u'Reactor', u'sighting', u'neighbor', u'UD', u'tomb', u'emperor', u'Kendals', u'Boulevard', u'Schnell', u'secondmost', u'son', u'Iraqi', u'roads', u'herbalist', u'fought', u'Simpson', u'pitcher', u'specialty', u'Archivist', u'Luciano', u'Minaj', u'Helena', u'abolitionist', u'general', u'Cabot', u'Darwin', u'dealer', u'Imam', u'englishman', u'Jr.', u'XXIII', u'actor', u'politicians', u'satirist', u'Lodensteijn', u'star', u'Karim', u'chairperson', u'mosaics', u'minister']\n",
      "Number:  [u'bagpipe', u'similarity', u'lack', u'resistance', u'month', u'highways', u'deadline', u'ammonia', u'bars', u'increase', u'zone', u'icons', u'sniper', u'Buffett', u'shaft', u'elevations', u'Origin', u'level', u'solution', u'Index', u'escalation', u'Europes', u'estimates', u'rate', u'cost', u'scroe', u'machines', u'sun', u'Merkel', u'anniversary', u'thickness', u'Socio', u'public', u'temperatures', u'ration', u'Libya', u'Brasilia', u'error', u'hours', u'operating', u'tuition', u'precursor', u'amount', u'advertising', u'celebrants', u'punishment', u'criticism', u'diameter', u'namee', u'pavement', u'regiment', u'Hanover', u'federlism', u'Nigeria', u'total', u'tools', u'standing', u'attendance', u'beginning', u'guideline', u'asses', u'spike', u'rainfall', u'integers', u'abundance', u'involve', u'intake', u'hour', u'Locke', u'half-life', u\"'Pra\", u'ECCE', u'revenues', u'ranking', u'share', u'numbers', u'slip', u'Years', u'AFL', u'axis', u'Welsh', u'methodology', u'earnings', u'significance', u'fare', u'Expedition-1', u'clone', u'spot', u'aborigines', u'representations', u'Churchill', u'Lilius', u'Tennessee', u'temp', u'Greece', u'turnover', u'wavelengths', u'calibre', u'timing', u'willow', u'Delhi', u'coordinates', u'crew', u'Spain', u'reveal', u'commitment', u'EYS', u'Gabon', u'effects', u'slippage', u'day', u'dielectric', u'continuum', u'liberia', u'Globe', u'composition', u'magnitude', u'wage', u'accounts', u'subset', u'prohibit', u'weight', u'gun', u'pecentage', u'yield', u'navy', u'wavelength', u'margins', u'collector', u'FlaK', u'dominates', u'space', u'Frued', u'medicine', u'phenolic', u'mechanisms', u'isotope', u'Tucson', u'formation', u'estimate', u'turnout', u'widths', u'positioning', u'Arsenal', u'length', u'Montevideo', u'margin', u'retail', u'speeds', u'hydrides', u'number', u'rank', u'date', u'Shiraz', u'downside', u'specificity', u'Genesis', u'size', u'RMP', u'Diamond', u'Iran', u'temperature', u'plains', u'Rakhine', u'codons', u'rates', u'identity', u'calculations', u'bounty', u'percentage', u'ceiling', u'statement', u'season', u'Guinea-Bissau', u'rifle', u'population', u'distance', u'hike', u'KU', u'argument', u'Odeon', u'need', u'concentration', u'Valley', u'Eurozone', u'angle', u'instance', u'post-punk', u'materials', u'accuracy', u'Jones', u'price', u'measures', u'Frederick', u'Minds', u'mouth', u'pair', u'seasons', u'drought', u'damage', u'D+', u'average', u'GDP', u'request', u'newcomers', u'emperature', u'motorways', u'bracket', u'Springs', u'quantity', u'rating', u'restriction', u'brother', u'threshold', u'fine', u'find', u'ratio', u'Austin', u'winner', u'proportion', u'bases', u'Historians', u'Liberia', u'incentives', u'vowels', u'GPA', u'reporters', u'OMOV', u'stability', u'EQ', u'circulation', u'chirigotas', u'grades', u'sidearm', u'allegation', u'contain', u'release', u'resonance', u'requirement', u'set', u'edition', u'Vedanta', u'radius', u'lifespan', u'hole', u'score', u'Huxley', u'UNAIDS', u'Glimm', u'Browning', u'blame', u'efficiency', u'haplogroup', u'debt', u'isotopes', u'iPod', u'Thomson', u'auctions', u'Sepphoris', u'expression', u'load', u'suggest', u'point', u'snowfall', u'height', u'Was', u'boat', u'decline', u'Plan', u'make-up', u'trinity', u'life', u'efficacy', u'measles', u'gas', u'gap', u'expenditure', u'orchestras', u'divisions', u'landing', u'estimations', u'budget', u'value', u'Guptas', u'Cyprus', u'amoun', u'century', u'Imperial', u'neurons', u'brake', u'centennial', u'Valencia', u'Phillipines', u'Product', u'pay', u'quirk', u'parts', u'biologists', u'satellite', u'wires', u'centuries', u'valuation', u'rain', u'levels', u'Burmanisation', u'cycle', u'percentages', u'object', u'honor', u'savings', u'spectator', u'Jama', u'dose', u'speed', u'announcement', u'density', u'absorption', u'MYS', u'munition', u'demographic', u'Dome', u'improvement', u'BCE', u'balloons', u'monotheists', u'elevation', u'myth', u'capacities', u'measurement', u'Roberts', u'traffic', u'variants', u'precipitation', u'Flair', u'wavelenght', u'London', u'output', u'percentsge', u'liquidation', u'Brandenburg', u'shortcoming', u'Christensen', u'dimensions', u'measurements', u'audience', u'per', u'cloud', u'inclination', u'School', u'incidence', u'run', u'warlords', u'Beringia', u'perpendicular', u'Times', u'post', u'Loop', u'Hyderabad', u'extension', u'months', u'ranges', u'Plymouth', u'range', u'expectancy', u'coverage', u'decrease', u'capable', u'rounds', u'diameters', u'altitude', u'Entertainment', u'custom', u'inconsistency', u'fraction', u'crews', u'Counties', u'tally', u'Detroit', u'count', u'Invader', u'characteristic', u'Knesset', u'Africa', u'maximum', u'LER', u'limit', u'Boas', u'constant', u'sale', u'logo', u'lifetime', u'commentators', u'MSA', u'%', u'floor', u'stake', u'percent', u'portion', u'income', u'users', u'Suarez', u'Arnold', u'chance', u'scale', u'Rooney', u'Earth', u'Myanmar', u'age', u'Comcast', u'depth', u'mass', u'diagnosis', u'time', u'Bombycilla', u'resolution', u'profits', u'demodulator']\n",
      "Location:  [u'Canada', u'Manchuse', u'tombs', u'archaeologists', u'gang', u'Capital', u'settlement', u'Somaliland', u'birthplace', u'archdiocese', u'EST5EDT', u'catastrophe', u'providence', u'mosque', u'lawmakers', u'road', u'federation', u'connects', u'miners', u'Federalism', u'sunk', u'harbor', u'Arabs', u'venue', u'Caesar', u'settlers', u'garden', u'neighborhood', u'streets', u'rivers', u'aquifer', u'State', u'street', u'Korea', u'constitution', u'superpower', u'capital', u'Gampo', u'lacquer', u'Festino', u'compilation', u'Utrecht', u'path', u'earthquake', u\"'Scullers\", u'Rodman', u'snowbirds', u'derby', u'Continent', u'Wonder', u'Tuscon', u'Yangon', u'gateway', u'Australia', u'Hub', u'counties', u'possession', u'Bei', u'populations', u'towers', u'statutes', u'Confederate', u'accessories', u'trail', u'Gorbachev', u'town', u'Affair', u'tunnel', u'Sweden', u'Ashkenaz', u'Kuznetsov', u'mall', u'freedom', u'proof', u'estate', u'CAR', u'states', u'Forbes', u'dieseases', u'acts', u'Congo', u'bricks', u'palaces', u'beach', u'capitol', u'economy', u'mas', u'spelling', u'Petersen', u'geographies', u'manpower', u'Japanese', u'Middle', u'Party', u'Ptolemy', u'Purple', u'Kushans', u'bombing', u'disagreed', u'attraction', u'complex', u'combination', u'Bay', u'belt', u'Hospital', u'Tower', u'lineage', u'Sam', u'tiers', u'ports', u'legions', u'Communists', u'square', u'Organisation', u'tenth', u'thoroughfares', u'Michigan', u'factory', u'seaport', u'hill', u'expressway', u'G', u'Smiles', u'base', u'Architecture', u'conflicts', u'district', u'submarines', u'Nepal', u'Goring', u'Horn', u'connotation', u'Lama', u'relate', u'municipality', u'primary', u'comprises', u'Gilbert', u'city', u'metalwork', u'seat', u'relations', u'PVA', u'Entente', u'dogs', u'ecotourist', u'hub', u'hotel', u'Podgorica', u'part', u'Rajasthani', u'inland', u'monarchies', u'nations', u'steet', u'Zaire', u'Peter', u'powers', u'supercontinent', u'bridge', u'motivation', u'palace', u'suspicious', u'mine', u'headland', u'Yama', u'mountain', u'jurisdictions', u'country/territory', u'zoo', u'Congregation', u'Germany', u'holders', u'Bronck', u'province', u'combat', u'monastery', u'synonym', u'neighborhoods', u'alarm', u'drive', u'freeway', u'Canon', u'Pakistan', u'Byzantines', u'Union', u'bring', u'Quasm', u'lilangeni', u'soviets', u'Kahuta', u'ground', u'Province', u'subgenre', u'terminal', u'notes', u'get', u'stop', u'coast', u'River', u'areas', u'hall', u'scene', u'countries', u'Washington', u'bison', u'river', u'Mongols', u'sea', u'John', u'constellation', u'langauge', u'Park', u'state', u'Freedom', u'infrastructure', u'confusion', u'Luftwaffe', u'southeast', u'hypothesis', u'Shaokun', u'outer', u'cities', u'undermine', u'Kangra', u'goddess', u'installation', u'restaurant', u'fault', u'region', u'declare', u'marchers', u'KMC', u'royal', u'colony', u'community', u'canyon', u'village', u'ADGB', u'provinces', u'airlines', u'stadium', u'Reporters', u'borders', u'territory', u'trend', u'location', u'direction', u'Moldova', u'World', u'independence', u'plain', u'heartland', u'Jurisdiction', u'Reagan', u'US-30', u'country', u'Taiwan', u'Avenue', u'decolonization', u'site', u'surface', u'Wood', u'partner', u'waterway', u'alliances', u'capture', u'borough', u'italy', u'border', u'airport', u'Coastline', u'Island', u'commune', u'Shaivism', u'Persis', u'hand', u'suburb', u'Airport', u'nation', u'database', u'Miller', u'ocean', u'States', u'centres', u'camps', u'comprise', u'gods', u'Mexicans', u'Territory', u'continent', u'atoll', u'blow', u'conclude', u'lake', u'Victoria', u'airfield', u'Connecticut', u'plateau', u'homeland', u'Front', u'confederacy', u'kingdom', u'landings', u'Enlai', u'protesters', u'Drake', u'Ortega', u'harbour', u'railroad', u'pier', u'Reduit', u'county', u'Albania', u'Titograd', u'exclave', u'tribes', u'NAFTA', u'reaches', u'Perry', u'spring', u'Qiang', u'protectorate', u'recognition', u'faction', u'councel', u'Mahan', u'intersections', u'temple', u'Kota', u'metropolis', u'Pangaea', u'Shibell', u'lakes', u'Range', u'convent', u'om', u'island', u'city-states', u'militia', u'islands', u'basin', u'Samanid', u'Kazusanosuke', u'promiss', u'lands', u'transistron', u'Newars', u'revolutionaries', u'Abdullah', u'laborers', u'right', u'promise', u'canal', u'area', u'Ming', u'Serval', u'valley', u'Museum', u'mountains', u'north', u'continents', u'January', u'hemisphere', u'Namibia', u'hottest', u'blockading', u'sutras', u'partitioning', u'terminus', u'places', u'Wall', u'Britain', u'Prussians', u'Terminal', u'Edward', u'ecoregion', u'priory', u'burrough', u'Heinrich', u'Tsongas', u'exporter', u'Daytona', u'vocabulary', u'annex', u'Country', u'April', u'peak', u'Retable', u'Melborne', u'land', u'Desert', u'Mission', u'mercenary', u'Street', u'gardens']\n"
     ]
    }
   ],
   "source": [
    "threshold = 1\n",
    "for (w,n) in year_headword.items():\n",
    "    if w in organization_headword:\n",
    "        if n >= organization_headword.get(w):\n",
    "            del organization_headword[w]\n",
    "        else:\n",
    "            del year_headword[w]\n",
    "for (w,n) in year_headword.items():\n",
    "    if w in person_headword:\n",
    "        if n >= person_headword.get(w):\n",
    "            del person_headword[w]\n",
    "        else:\n",
    "            del year_headword[w]\n",
    "for (w,n) in year_headword.items():\n",
    "    if w in number_headword:\n",
    "        if n >= number_headword.get(w):\n",
    "            del number_headword[w]\n",
    "        else:\n",
    "            del year_headword[w]\n",
    "for (w,n) in year_headword.items():\n",
    "    if w in location_headword:\n",
    "        if n >= location_headword.get(w):\n",
    "            del location_headword[w]\n",
    "        else:\n",
    "            del year_headword[w]\n",
    "            \n",
    "for (w,n) in organization_headword.items():\n",
    "    if w in person_headword:\n",
    "        if n >= person_headword.get(w):\n",
    "            del person_headword[w]\n",
    "        else:\n",
    "            del organization_headword[w]\n",
    "for (w,n) in organization_headword.items():\n",
    "    if w in number_headword:\n",
    "        if n >= number_headword.get(w):\n",
    "            del number_headword[w]\n",
    "        else:\n",
    "            del organization_headword[w]\n",
    "for (w,n) in organization_headword.items():\n",
    "    if w in location_headword:\n",
    "        if n >= location_headword.get(w):\n",
    "            del location_headword[w]\n",
    "        else:\n",
    "            del organization_headword[w]\n",
    "            \n",
    "for (w,n) in person_headword.items():\n",
    "    if w in number_headword:\n",
    "        if n >= number_headword.get(w):\n",
    "            del number_headword[w]\n",
    "        else:\n",
    "            del person_headword[w]\n",
    "for (w,n) in person_headword.items():\n",
    "    if w in location_headword:\n",
    "        if n >= location_headword.get(w):\n",
    "            del location_headword[w]\n",
    "        else:\n",
    "            del person_headword[w]\n",
    "\n",
    "for (w,n) in number_headword.items():\n",
    "    if w in location_headword:\n",
    "        if n >= location_headword.get(w):\n",
    "            del location_headword[w]\n",
    "        else:\n",
    "            del number_headword[w]\n",
    "            \n",
    "for (w,n) in year_headword.items():\n",
    "    if n < threshold:\n",
    "        del year_headword[w]\n",
    "for (w,n) in organization_headword.items():\n",
    "    if n < threshold:\n",
    "        del organization_headword[w]\n",
    "for (w,n) in person_headword.items():\n",
    "    if n < threshold:\n",
    "        del person_headword[w]\n",
    "for (w,n) in number_headword.items():\n",
    "    if n < threshold:\n",
    "        del number_headword[w]\n",
    "for (w,n) in location_headword.items():\n",
    "    if n < threshold:\n",
    "        del location_headword[w]\n",
    "\n",
    "\n",
    "location_list = location_headword.keys()\n",
    "number_list = number_headword.keys()\n",
    "organization_list = organization_headword.keys()\n",
    "name_list = person_headword.keys()\n",
    "year_list = year_headword.keys()\n",
    "\n",
    "print 'Year: ',year_headword.keys()\n",
    "print 'Organ: ',organization_headword.keys()\n",
    "print 'Person: ',person_headword.keys()\n",
    "print 'Number: ',number_headword.keys()\n",
    "print 'Location: ',location_headword.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# year_list = [u'years', u'year', u'decade', u'span']\n",
    "# name_list = [u'composer', u'figure', u'president', u'architect', u'singer', u'writer', u'artist', u'author', u'ruler', u'philosopher', u'leader', u'Darwin', u'actor']\n",
    "# number_list = [u'month', u'increase', u'level', u'rate', u'cost', u'amount', u'Nigeria', u'share', u'date', u'Greece', u'day', u'Tucson', u'temperature', u'length', u'number', u'rank', u'size', u'percentage', u'season', u'population', u'price', u'average', u'GDP', u'ratio', u'score', u'point', u'value', u'century', u'centuries', u'speed', u'density', u'range', u'fraction', u'Detroit', u'limit', u'percent', u'portion', u'income', u'age', u'time']\n",
    "# location_list = [u'venue', u'neighborhood', u'street', u'capital', u'airport', u'town', u'states', u'district', u'city', u'part', u'province', u'areas', u'countries', u'river', u'state', u'cities', u'region', u'territory', u'location', u'country', u'site', u'nation', u'continent', u'kingdom', u'island', u'road', u'area', u'county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_list = location_list + ['country','county','district','city']\n",
    "number_list = number_list + ['version','size','msa','far','much','ration','time','many','population','large','percent','average','day','decade','big','long']\n",
    "name_list = name_list + ['name','center','president','denominations','denomination','film','broadcaster','pitcher','commentator']\n",
    "year_list = year_list + ['years','year','era']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer_pos_question(pos):\n",
    "    new_pos = []\n",
    "    for (word,wtype) in pos:\n",
    "        if word.lower() == 'what' or word.lower() == 'what\\'s':\n",
    "            new_pos.append((word,'WHAT'))\n",
    "        elif word.lower() == 'do' or word.lower() == 'does' or word.lower() == 'did':\n",
    "            new_pos.append((word,'DO'))\n",
    "        elif word in number_list:\n",
    "            new_pos.append((word,'NUMBER'))\n",
    "        elif word in year_list:\n",
    "            new_pos.append((word,'YEAR'))\n",
    "        elif word in name_list:\n",
    "            new_pos.append((word,'NAME'))\n",
    "        elif word in location_list:\n",
    "            new_pos.append((word,'LOC'))\n",
    "        elif word.lower() == 'is' or word.lower() == 'was' or word.lower() == 'are' or word.lower() == 'were' or word.lower() == 'be':\n",
    "            new_pos.append((word,'BE'))\n",
    "        elif word.lower() == 'when':\n",
    "            new_pos.append((word,'WHEN'))\n",
    "        elif word.lower() == 'where':\n",
    "            new_pos.append((word,'WHERE'))\n",
    "        elif word.lower() == 'can':\n",
    "            new_pos.append((word,'CAN'))\n",
    "        elif word.lower() == 'how':\n",
    "            new_pos.append((word,'HOW'))\n",
    "        elif word.lower() == 'who' or word.lower() == 'whom' or word.lower() == 'whose'  or word.lower() == 'whos':\n",
    "            new_pos.append((word,'WHO'))\n",
    "        elif word.lower() == 'which':\n",
    "            new_pos.append((word,'WHICH'))\n",
    "        elif word.lower() == 'define':\n",
    "            new_pos.append((word,'DEFINE'))\n",
    "        elif word.lower() == 'should':\n",
    "            new_pos.append((word,'SHOULD'))\n",
    "        elif word.lower() == 'why' or word.lower() == 'wy':\n",
    "            new_pos.append((word,'WHY'))\n",
    "        else:\n",
    "            new_pos.append((word,wtype))\n",
    "    return new_pos\n",
    "\n",
    "def get_continuous_chunks(text):\n",
    "    t = copy.deepcopy(text)\n",
    "    pos = pos_tag(nltk.word_tokenize(t))\n",
    "    pos = transfer_pos_question(pos)\n",
    "    #print pos\n",
    "    grammar = r\"\"\"\n",
    "                WHAT: \n",
    "                    {<WHAT>}\n",
    "                    {<WHICH>}\n",
    "                    {<DEFINE>}\n",
    "                WHO:\n",
    "                    {<WHO>}\n",
    "                    {<WHAT><BE>?<DT>?<JJ|RB>*<NAME>}\n",
    "                    {<WHAT><JJ|RB>*<NN>+<NAME>}\n",
    "                NUMBER:\n",
    "                    {<WHICH><NUMBER>}\n",
    "                    {<HOW><NUMBER>}\n",
    "                    {<WHAT><BE>?<DT>?<JJ>?<NN>*<JJ>?<NUMBER>}\n",
    "                WHEN:\n",
    "                    {<WHICH><YEAR>}\n",
    "                    {<WHAT><BE>?<DT>?<JJ>?<NN>*<JJ>?<YEAR>}\n",
    "                    {<WHEN>}\n",
    "                WHERE:\n",
    "                    {<WHERE>}\n",
    "                    {<WHAT><LOC>}\n",
    "                    {<WHAT><BE>?<DT>?<RBS>?<JJ>?<LOC>}\n",
    "                HOW:\n",
    "                    {<CAN>}\n",
    "                    {<DO>}\n",
    "                    {<SHOULD>}\n",
    "                    {<WHY>}\n",
    "                    {<HOW>}\n",
    "\n",
    "                \"\"\"\n",
    "    cp = nltk.RegexpParser(grammar) \n",
    "    result = []\n",
    "    tree = cp.parse(pos)\n",
    "    #record the position of pos\n",
    "    #print pos\n",
    "    flag = 0\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() != 'S':\n",
    "            phrase = u''\n",
    "            for word,pos in subtree.leaves():\n",
    "                if word == ',':\n",
    "                    phrase = phrase + word\n",
    "                else:\n",
    "                    phrase = phrase + u' '\n",
    "                    phrase = phrase + word\n",
    "            result.append((subtree.label(),phrase[1:]))         \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer_pos_sentence(pos):\n",
    "    new_pos = []\n",
    "    \n",
    "    for (word,wtype) in pos:\n",
    "        time_pattern = re.compile(r'[0-9]{4}s?')\n",
    "        if word.lower() == 'and' or word.lower() == 'or':\n",
    "            new_pos.append((word,'POSICC'))\n",
    "        elif word.lower() == 'with':\n",
    "            new_pos.append((word,'WITH'))\n",
    "        elif word.lower() == 'a' or word.lower() == 'an':\n",
    "            new_pos.append((word,'A'))\n",
    "        elif word == '\"':\n",
    "            new_pos.append((word,'\"'))\n",
    "        elif word == 'minutes' or word == 'March':\n",
    "            new_pos.append((word,'TIME'))\n",
    "        elif time_pattern.search(word):\n",
    "            new_pos.append((word,'TIME'))\n",
    "        elif word == 'around':\n",
    "            new_pos.append((word,'AROUND'))\n",
    "        elif word == 'mm':\n",
    "            new_pos.append((word,'CD')) \n",
    "        else:\n",
    "            new_pos.append((word,wtype))\n",
    "    return new_pos\n",
    "\n",
    "def get_continuous_chunks_sentence(text,texttype):\n",
    "    t = copy.deepcopy(text)\n",
    "    pos =  pos_tag(nltk.word_tokenize(t))\n",
    "    if texttype==0:\n",
    "        #WHAT\n",
    "        pos = transfer_pos_sentence(pos)\n",
    "        grammar = r\"\"\"\n",
    "                    J:\n",
    "                        {<JJ.*><VBN>}\n",
    "                        {<JJ.*><POSICC><JJ.*>}   \n",
    "                        {<JJ.*>+}\n",
    "                        {<NN.*><POS>}\n",
    "                    N:\n",
    "                        {<CD>+<NN.*>}\n",
    "                        {<A>?<NN.*>?<J>?<NN.*>+}\n",
    "                        <\\\">{<A>?<J>?<NN.*>+}<\\\">\n",
    "                    COMBON:\n",
    "                        {(<N><,>)*<N><,>?<POSICC><N>}\n",
    "                    NWC:\n",
    "                        {<N><WITH><COMBON>}\n",
    "                    \"\"\"\n",
    "    cp = nltk.RegexpParser(grammar) \n",
    "    result = []\n",
    "    poss = copy.deepcopy(pos)\n",
    "    tree = cp.parse(pos)\n",
    "    #record the position of pos\n",
    "    flag = 0\n",
    "    for i in range (len(tree)):   \n",
    "        if type(tree[i]) != tuple:\n",
    "            subtree = tree[i]\n",
    "            if texttype==0 and subtree.label() != 'S':\n",
    "                phrase = u''\n",
    "                for word,pos in subtree.leaves():\n",
    "                    if word == ',':\n",
    "                        phrase = phrase + word\n",
    "                    else:\n",
    "                        phrase = phrase + u' '\n",
    "                        phrase = phrase + word\n",
    "                result.append((subtree.label(),phrase[1:]))\n",
    "                #print subtree.label(),phrase\n",
    "            elif subtree.label() != 'S':\n",
    "                phrase = u' '.join([word for word,pos in subtree.leaves()])\n",
    "                result.append((subtree.label(),phrase))      \n",
    "    return poss,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NER\n",
    "'''\n",
    "time_word = [\n",
    "    'one','two','three','four','five','six','seven','eight','nine',\n",
    "    'January','February','March','April','May','June','July','August','September','October','November','December',\n",
    "    'million','billion',\n",
    "    'minutes','hours','years','times',\n",
    "    'mm','miles','inches','foot','feet',\n",
    "    'late','early','around','over',\n",
    "    'persons','seasons','square',\n",
    "    'spring','summer','fall','autumn','winter'\n",
    "]\n",
    "\n",
    "location_word = [\n",
    "    'southwest','southeast','northwest','northeast'\n",
    "]\n",
    "\n",
    "conjunction_word = ['and','of']\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import re\n",
    "def input_NER():\n",
    "    stanford_dir = os.path.join('stanford-ner-2016-10-31')\n",
    "    jarfile = os.path.join(stanford_dir,'stanford-ner.jar')\n",
    "    modelfile = os.path.join(stanford_dir,'classifiers/english.all.3class.distsim.crf.ser.gz')\n",
    "    return modelfile,jarfile\n",
    "model,jar = input_NER()\n",
    "st = StanfordNERTagger(model,jar)\n",
    "\n",
    "def analyse_NER(ner_sentences):\n",
    "    result_sentences = []\n",
    "    for ner_sentence in ner_sentences:\n",
    "        result_sentence = []\n",
    "        perv_type = u'O'\n",
    "        word = u''\n",
    "        conjunction = u''\n",
    "        conjunc_flag = False\n",
    "        for index,(entity,etype) in enumerate(ner_sentence):\n",
    "            if perv_type == u'O' and etype != u'O':              \n",
    "                perv_type = etype\n",
    "                word = entity + u' '\n",
    "            elif word != u'':\n",
    "                if etype == u'O':\n",
    "                    if entity not in conjunction_word:\n",
    "                        result_sentence.append((word[:-1],perv_type))\n",
    "                        word = u''\n",
    "                        perv_type = u'O'\n",
    "                        if conjunction != u'':\n",
    "                            conjunction = u''\n",
    "                            conjunc_flag = False\n",
    "                    else:\n",
    "                        if conjunction != u'':\n",
    "                            conjunction = u''\n",
    "                            conjunc_flag = False\n",
    "                        else:\n",
    "                            conjunction = entity\n",
    "                            conjunc_flag = True\n",
    "                elif etype != perv_type:\n",
    "                    result_sentence.append((word[:-1],perv_type))\n",
    "                    word = entity + u' '\n",
    "                    perv_type = etype\n",
    "                    conjunction = u''\n",
    "                    conjunc_flag = False\n",
    "                elif etype == perv_type:\n",
    "                    if conjunc_flag:\n",
    "                        if conjunction == u',':\n",
    "                            word = word[:-1] + conjunction + u' ' + entity + u' '\n",
    "                        else:\n",
    "                            word = word + conjunction + u' ' + entity + u' '\n",
    "                        conjunction = u''\n",
    "                        conjunc_flag = False\n",
    "                    else:\n",
    "                        if entity in ['%'] or word == u'$ ':\n",
    "                            word = word[:-1] + entity + u' '\n",
    "                        else:\n",
    "                            word = word + entity + u' '\n",
    "        if word != u'':\n",
    "            result_sentence.append((word[:-1],perv_type))\n",
    "        result_sentences.append(result_sentence)      \n",
    "    return result_sentences\n",
    "\n",
    "def parse_NER(ner_sentences):\n",
    "    pattern_number = re.compile(r'([0-9]+|\\%|\\$)')\n",
    "    year_number = re.compile(r'([0-9]{4}s?)')\n",
    "    result_sentences = []\n",
    "    for ner_sentence in ner_sentences:\n",
    "        result_sentence = []\n",
    "        for index,(entity,etype) in enumerate(ner_sentence):\n",
    "            if entity != u'':\n",
    "                entity.replace(u'\\u2013',u'-')\n",
    "                entity.replace(u'\\u2014',u'-')\n",
    "                entity.replace(u'\\u2212',u'-')\n",
    "                entity.replace(u'\\u2044',u'%')\n",
    "                if etype == u'O':\n",
    "                    if year_number.search(entity):\n",
    "                        result_sentence.append((entity,u'YEAR'))\n",
    "                    elif pattern_number.search(entity) or entity in time_word:\n",
    "                        result_sentence.append((entity,u'NUMBER'))\n",
    "                    elif u'-' in entity:\n",
    "                        word_seperate = entity.split(u'-')\n",
    "                        for word in word_seperate:\n",
    "                            if word in time_word:\n",
    "                                result_sentence.append((entity,u'NUMBER'))\n",
    "                                break\n",
    "                    elif entity in location_word:\n",
    "                        result_sentence.append((entity,u'LOCATION'))\n",
    "                    elif index == 0 and entity.lower() not in stopwords:\n",
    "                        result_sentence.append((entity,u'ORGANIZATION'))\n",
    "                    elif index != 0 and entity[0].isupper():\n",
    "                        result_sentence.append((entity,u'ORGANIZATION'))\n",
    "                    else:\n",
    "                        result_sentence.append((entity,etype))\n",
    "                elif entity in ['(',')']:\n",
    "                    result_sentence.append((entity,u'O'))\n",
    "                else:\n",
    "                    result_sentence.append((entity,etype))\n",
    "        result_sentences.append(result_sentence)\n",
    "        \n",
    "    return analyse_NER(result_sentences)\n",
    "\n",
    "def extract_NER(parse_ner_sentence,mode):\n",
    "    result = []\n",
    "    if mode == 0:\n",
    "        #PERSON\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'PERSON':\n",
    "                result.append(entity)\n",
    "    elif mode == 1:\n",
    "        #NUMBER\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'NUMBER':\n",
    "                result.append(entity)\n",
    "    elif mode == 2:\n",
    "        #LOCATION\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'LOCATION':\n",
    "                result.append(entity)\n",
    "    elif mode == 3:\n",
    "        #ORGANIZATION\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'ORGANIZATION':\n",
    "                result.append(entity)\n",
    "    elif mode == 4:\n",
    "        #YEAR\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'YEAR':\n",
    "                result.append(entity)\n",
    "    return result\n",
    "\n",
    "def parse_token(token_sentence):\n",
    "    result = []\n",
    "    for index,word in enumerate(token_sentence):\n",
    "        if index != 0 and index != (len(token_sentence)-1) and word == u'.':\n",
    "            last_word = result[-1]\n",
    "            last_word = last_word + u'.'\n",
    "            result = result[:-1]\n",
    "            result.append(last_word)\n",
    "        else:\n",
    "            result.append(word)\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_rule_1(entity,query):\n",
    "    #lower scores for content words also appear in the query\n",
    "    count = 0\n",
    "    length = len(entity)\n",
    "    for word in entity:\n",
    "        word = lemmatize(word.lower())\n",
    "        if word not in stopwords:\n",
    "            if word in query:\n",
    "                count += 1\n",
    "    if length == 0:\n",
    "        score = 0\n",
    "    else:\n",
    "        score = 1 - float(count)/length\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def get_open_class_words(query):\n",
    "    result = []\n",
    "    for index in range(len(query)):\n",
    "        if query[index] not in stopwords:\n",
    "            if query[index] not in string.punctuation:\n",
    "                result.append(query[index])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_rule_3(answer_sentence,sentence,entity,query):\n",
    "    #higher scores for closer distance between an entity and the headword\n",
    "    #step 1: using a filter to extract \"useful\" open-class words\n",
    "    results = get_open_class_words(query)\n",
    "    sent = sentence\n",
    "    original_sent = answer_sentence\n",
    "    entity_loc = []\n",
    "    query_loc = []\n",
    "    for word in entity:\n",
    "        if word in original_sent:\n",
    "            entity_loc.append(original_sent.index(word))\n",
    "    for q in results:\n",
    "        if q in sent:\n",
    "            query_loc.append(sent.index(q))\n",
    "    min_dist = len(original_sent)\n",
    "    if query_loc != []:\n",
    "        for i in query_loc:\n",
    "            for j in entity_loc:\n",
    "                dist = abs(i - j)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    \n",
    "    return 1 - float(min_dist)/len(original_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def screen_out_answer_WHAT(result):\n",
    "    answer_list = []\n",
    "    for wtype, word in result:\n",
    "        if wtype != 'J':\n",
    "            answer_list.append(word)\n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "answers = []\n",
    "for index in range(len(test)):\n",
    "    print index\n",
    "    article = test[index]\n",
    "    qas = article['qa']\n",
    "    sentences = article['sentences']\n",
    "    token_sentences = copy.deepcopy(sentences)\n",
    "    for i in range(len(sentences)):\n",
    "        token_sentences[i] = parse_token(nltk.word_tokenize(token_sentences[i]))\n",
    "    ner_sentences = st.tag_sents(token_sentences)\n",
    "    parse_ner_sentences = parse_NER(ner_sentences)\n",
    "    for i in range(len(qas)):\n",
    "        qa = qas[i]\n",
    "        anss = []\n",
    "        scs = []\n",
    "        id = qa['id']\n",
    "        #the amount of extract sentences\n",
    "        amount = 4\n",
    "        for ii in range(amount):\n",
    "            if result_sentences_weight[index][i][ii] != 0:\n",
    "                weight = float(result_sentences_weight[index][i][ii])/sum(result_sentences_weight[index][i])\n",
    "            else:\n",
    "                weight = 0\n",
    "            answer_sentence = sentences[result_sentences[index][i][ii]]\n",
    "            answer_sentence_id = result_sentences[index][i][ii]\n",
    "            text_question = qa['question']\n",
    "            result = get_continuous_chunks(text_question)\n",
    "\n",
    "            if result != []:\n",
    "                wtype,word = result[0]\n",
    "                if wtype == 'NUMBER':\n",
    "                    answer_list = extract_NER(parse_ner_sentences[answer_sentence_id],1)\n",
    "                    if answer_list == []:\n",
    "                        answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],3)\n",
    "                elif wtype == 'WHO':\n",
    "                    answer_list = extract_NER(parse_ner_sentences[answer_sentence_id],0)\n",
    "                    if answer_list == []:\n",
    "                        answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],2)\n",
    "                        answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],3)\n",
    "                elif wtype == 'WHERE':\n",
    "                    answer_list = extract_NER(parse_ner_sentences[answer_sentence_id],2)\n",
    "                    if answer_list == []:\n",
    "                        answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],0)\n",
    "                        answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],3)\n",
    "                elif wtype == 'WHEN':\n",
    "                    answer_list = extract_NER(parse_ner_sentences[answer_sentence_id],4)\n",
    "                else:\n",
    "                    #what, or other types\n",
    "                    answer_list = extract_NER(parse_ner_sentences[answer_sentence_id],3)\n",
    "                    if answer_list == []:\n",
    "                        answer_sentence = sentences[answer_sentence_id]\n",
    "                        wpos,wresult = get_continuous_chunks_sentence(answer_sentence,0)\n",
    "                        answer_list = screen_out_answer_WHAT(wresult)\n",
    "\n",
    "            if answer_list != []:            \n",
    "                query = copy.deepcopy(text_question)\n",
    "                query = nltk.word_tokenize(query)\n",
    "                #token the answer sentence and copy it for further usage\n",
    "                answer_sentence = nltk.word_tokenize(answer_sentence)\n",
    "                sentence = copy.deepcopy(answer_sentence)\n",
    "\n",
    "                for query_index in range(len(query)):\n",
    "                    query[query_index] = lemmatize(query[query_index].lower())\n",
    "                for sent_index in range(len(sentence)):\n",
    "                    sentence[sent_index] = lemmatize(sentence[sent_index].lower())\n",
    "\n",
    "                scores_1 = []\n",
    "                scores_3 = []\n",
    "                scores = []\n",
    "                \n",
    "                for entity in answer_list:\n",
    "                    entity = nltk.word_tokenize(entity) \n",
    "                    score1 = rank_rule_1(entity,query)\n",
    "                    scores_1.append(score1)\n",
    "                    #answer_sentence is the original version and sentence is preprocessed\n",
    "                    score3 = rank_rule_3(answer_sentence,sentence,entity,query)\n",
    "                    scores_3.append(score3)\n",
    "                    w1 = 0.2\n",
    "                    w3 = 1 - w1\n",
    "                    if score1 == 0:\n",
    "                        score3 = 0\n",
    "                    total = w1 * score1 + w3 * score3\n",
    "                    scores.append(total)\n",
    "                answer = answer_list[scores.index(max(scores))]\n",
    "                sc = max(scores)*weight\n",
    "\n",
    "            else:\n",
    "                answer = answer_sentence\n",
    "                sc = 0\n",
    "            anss.append(answer)\n",
    "            scs.append(sc)\n",
    "        ans = anss[scs.index(max(scs))]\n",
    "        \n",
    "        ids.append(id)\n",
    "        answers.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(answers)):\n",
    "    answers[i] = answers[i].replace(',','-COMMA-')\n",
    "    answers[i] = answers[i].replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_result(filename):\n",
    "\n",
    "    predictions_file = open(filename, \"wb\")\n",
    "    open_file_object = csv.writer(predictions_file)\n",
    "    open_file_object.writerow([\"id\",\"answer\"])\n",
    "    for i in range(len(answers)):\n",
    "        open_file_object.writerow([ids[i], answers[i].encode(\"utf-8\")])\n",
    "    predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_result(\"result_enhance_524.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-COMMA-300\n"
     ]
    }
   ],
   "source": [
    "print answers[144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
