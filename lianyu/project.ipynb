{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get document frequency for terms in the same article/instance; and get each sentence's BOW; and get each question's BOW;\n",
    "#get each sentence's length; get each article's average length of sentences\n",
    "import csv\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "import nltk\n",
    "from math import log\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.spatial.distance import cosine as cos_distance\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tag import StanfordNERTagger\n",
    "def get_BOW(text):\n",
    "    BOW = {}\n",
    "    for word in text:\n",
    "        BOW[word] = BOW.get(word,0) + 1\n",
    "    return BOW\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "def input_data():\n",
    "    base_path = os.path.join('')\n",
    "    train_file = base_path + 'QA_train.json'\n",
    "    train_data = json.load(open(train_file))\n",
    "    test_file = base_path + 'QA_test.json'\n",
    "    test_data = json.load(open(test_file))\n",
    "    dev_file = base_path + 'QA_dev.json'\n",
    "    dev_data = json.load(open(dev_file))\n",
    "\n",
    "    return train_data,test_data,dev_data\n",
    "def transform_text(text):\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [lemmatize(word.lower()) for word in text]\n",
    "    for word in text:\n",
    "        if word in stopwords:\n",
    "            text.remove(word)\n",
    "    return text\n",
    "def get_Docfrequency_SentenceBOW(dataset):\n",
    "    #save dics, each dictionary contains document frequencies for all terms in the same article\n",
    "    question_list = []\n",
    "    #save lists, each list represent an article, saving sentences' bow\n",
    "    total_sentence_bow = []\n",
    "    #save lists, each list represent an article, saving questions' bow\n",
    "    total_question_bow = []\n",
    "    #save lists, each list represent all sentences' lengthes.\n",
    "    sent_lengthes = []\n",
    "    #save a list, each item represents the average length of sentences\n",
    "    avg_lengthes = []\n",
    "    #\n",
    "    answer_id = []\n",
    "    \n",
    "    for article in dataset:\n",
    "        #Docfrequency\n",
    "        article_dic = defaultdict(list)\n",
    "        keyterms = [] #save all distinct terms in questions\n",
    "        \n",
    "        #SentenceBOW\n",
    "        bow_list = []\n",
    "        \n",
    "        #QuestionBOW\n",
    "        que_list = []\n",
    "        \n",
    "        #SentenceLength\n",
    "        sent_len = []\n",
    "        \n",
    "        #TotalLength\n",
    "        total_len = 0\n",
    "        \n",
    "        #RightAnser\n",
    "        right_answer = []\n",
    "        \n",
    "        qas = article['qa']\n",
    "        sentences = article['sentences']\n",
    "        for qa in qas:\n",
    "            question = qa['question']\n",
    "            newquestion = transform_text(question)\n",
    "            #QuestionBOW\n",
    "            que_list.append(get_BOW(newquestion))\n",
    "            answer = qa['answer_sentence']\n",
    "            right_answer.append(answer)\n",
    "            \n",
    "            keyterms.extend(newquestion)\n",
    "        keyterms = set(keyterms)\n",
    "        \n",
    "        #save sentences' BOW in list sen_BOW\n",
    "        sen_words = []\n",
    "        for sent in sentences:\n",
    "            sent = transform_text(sent)\n",
    "            #Docfrequency\n",
    "            sen_words.append(sent)\n",
    "            \n",
    "            #SentenceBOW\n",
    "            bow_list.append(get_BOW(sent))\n",
    "            \n",
    "            #SentenceLength\n",
    "            sent_len.append(len(sent))\n",
    "            \n",
    "            #TotalLength\n",
    "            total_len += len(sent)\n",
    "            \n",
    "        \n",
    "        #calculate doc frequency    \n",
    "        for term in keyterms:\n",
    "            for i,bow in enumerate(sen_words):\n",
    "                if term in bow:\n",
    "                    article_dic[term].append(i)\n",
    "                    \n",
    "        #Docfrequency\n",
    "        question_list.append(article_dic)\n",
    "        #SentenceBOW\n",
    "        total_sentence_bow.append(bow_list)\n",
    "        #QuestionBOW\n",
    "        total_question_bow.append(que_list)\n",
    "        #SentenceLength\n",
    "        sent_lengthes.append(sent_len)\n",
    "        #AverageLength\n",
    "        avg_lengthes.append(float(total_len)/len(sentences))\n",
    "        #\n",
    "        answer_id.append(right_answer)\n",
    "        \n",
    "    return question_list, total_sentence_bow, total_question_bow, sent_lengthes, avg_lengthes, answer_id\n",
    "\n",
    "train,test,dev = input_data()\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "question_list, total_sentence_bow, total_question_bow, sent_lengthes, avg_lengthes, answer_id_list= get_Docfrequency_SentenceBOW(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def BM25(articles_index,k1,k2,b):\n",
    "    total_queries = len(total_question_bow[articles_index])\n",
    "    count = 0\n",
    "    for index in range(len(total_question_bow[articles_index])):\n",
    "        answer_id = answer_id_list[articles_index][index]\n",
    "        guess_id = find_max_score_sentence(articles_index,index,k1,k2,b)\n",
    "        if answer_id == guess_id:\n",
    "            count += 1   \n",
    "    accurancy = float(count)/total_queries  \n",
    "    return accurancy\n",
    "\n",
    "def find_max_score_sentence(articles_index,index,k1,k2,b):\n",
    "\n",
    "    query_dict = total_question_bow[articles_index][index]\n",
    "    max_score = 0\n",
    "    guess_sentence = 0\n",
    "    for index in range(len(total_sentence_bow[articles_index])):     \n",
    "        score = 0  \n",
    "        sentence_dict = total_sentence_bow[articles_index][index]\n",
    "        for word in query_dict:\n",
    "            document_fre_list = question_list[articles_index].get(word,None)\n",
    "            \n",
    "            \n",
    "            N = len(total_sentence_bow[articles_index])\n",
    "            n_qi = 0\n",
    "            if document_fre_list != None:\n",
    "                n_qi = len(document_fre_list)\n",
    "            else:\n",
    "                n_qi = 0\n",
    "            fi = sentence_dict.get(word,0)\n",
    "            qfi = query_dict.get(word,0)\n",
    "            dl = sent_lengthes[articles_index][index]\n",
    "            avgdl = avg_lengthes[articles_index]\n",
    "            \n",
    "            K = k1*(1-b+b*(float(dl)/avgdl)) \n",
    "            W = math.log((N-n_qi+0.5)/(n_qi+0.5))\n",
    "            R = (fi*(k1+1))/(fi+K)*qfi*(k2+1)/(qfi+k2)\n",
    "            score += W*R\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            guess_sentence = index\n",
    "    return guess_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy of BM25 with k1: 1.2  k2: 100  b: 0.15\n",
      "0.66398077963\n",
      "Accurancy of BM25 with k1: 1.2  k2: 100  b: 0.175\n",
      "0.664018843841\n",
      "Accurancy of BM25 with k1: 1.2  k2: 150  b: 0.15\n",
      "0.663956948666\n",
      "Accurancy of BM25 with k1: 1.2  k2: 150  b: 0.175\n",
      "0.663997476319\n",
      "Accurancy of BM25 with k1: 1.5  k2: 100  b: 0.15\n",
      "0.662413691899\n",
      "Accurancy of BM25 with k1: 1.5  k2: 100  b: 0.175\n",
      "0.662067586202\n",
      "Accurancy of BM25 with k1: 1.5  k2: 150  b: 0.15\n",
      "0.662413691899\n",
      "Accurancy of BM25 with k1: 1.5  k2: 150  b: 0.175\n",
      "0.662051588099\n"
     ]
    }
   ],
   "source": [
    "accurancy = 0.0\n",
    "\n",
    "k1_list = [1.2,1.5]\n",
    "k2_list = [100,150]\n",
    "b_list = [0.15,0.175]\n",
    "\n",
    "test_length = len(train)\n",
    "for k1 in k1_list:\n",
    "    for k2 in k2_list:\n",
    "        for b in b_list:\n",
    "            accurancy = 0.0\n",
    "            for i in range(0,test_length):\n",
    "                i_accurancy = BM25(i,k1,k2,b)\n",
    "                accurancy += i_accurancy\n",
    "            average_accurancy = accurancy/test_length\n",
    "            print \"Accurancy of BM25 with k1:\",k1,\" k2:\",k2,\" b:\",b\n",
    "            print average_accurancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
