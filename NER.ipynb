{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get document frequency for terms in the same article/instance; and get each sentence's BOW; and get each question's BOW;\n",
    "#get each sentence's length; get each article's average length of sentences\n",
    "import csv\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "import nltk\n",
    "from math import log\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.spatial.distance import cosine as cos_distance\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tag import StanfordNERTagger\n",
    "def get_BOW(text):\n",
    "    BOW = {}\n",
    "    for word in text:\n",
    "        BOW[word] = BOW.get(word,0) + 1\n",
    "    return BOW\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "def input_data():\n",
    "    base_path = os.path.join('data/')\n",
    "    train_file = base_path + 'QA_train.json'\n",
    "    train_data = json.load(open(train_file))\n",
    "    test_file = base_path + 'QA_test.json'\n",
    "    test_data = json.load(open(test_file))\n",
    "    dev_file = base_path + 'QA_dev.json'\n",
    "    dev_data = json.load(open(dev_file))\n",
    "\n",
    "    return train_data,test_data,dev_data\n",
    "def transform_text(text):\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [lemmatize(word.lower()) for word in text]\n",
    "    result = []\n",
    "    for word in text:\n",
    "        if word not in stopwords and word not in punctuations:\n",
    "            result.append(word)\n",
    "    return result\n",
    "def get_Docfrequency_SentenceBOW(dataset):\n",
    "    #save dics, each dictionary contains document frequencies for all terms in the same article\n",
    "    question_list = []\n",
    "    #save lists, each list represent an article, saving sentences' bow\n",
    "    total_sentence_bow = []\n",
    "    #save lists, each list represent an article, saving questions' bow\n",
    "    total_question_bow = []\n",
    "    #save lists, each list represent all sentences' lengthes.\n",
    "    sent_lengthes = []\n",
    "    #save a list, each item represents the average length of sentences\n",
    "    avg_lengthes = []\n",
    "    #\n",
    "    answer_id = []\n",
    "    \n",
    "    for article in dataset:\n",
    "        #Docfrequency\n",
    "        article_dic = defaultdict(list)\n",
    "        keyterms = [] #save all distinct terms in questions\n",
    "        \n",
    "        #SentenceBOW\n",
    "        bow_list = []\n",
    "        \n",
    "        #QuestionBOW\n",
    "        que_list = []\n",
    "        \n",
    "        #SentenceLength\n",
    "        sent_len = []\n",
    "        \n",
    "        #TotalLength\n",
    "        total_len = 0\n",
    "        \n",
    "        #RightAnser\n",
    "        right_answer = []\n",
    "        \n",
    "        qas = article['qa']\n",
    "        sentences = article['sentences']\n",
    "        for qa in qas:\n",
    "            question = qa['question']\n",
    "            newquestion = transform_text(question)\n",
    "            #QuestionBOW\n",
    "            que_list.append(get_BOW(newquestion))\n",
    "            answer = qa['answer_sentence']\n",
    "            right_answer.append(answer)\n",
    "            \n",
    "            keyterms.extend(newquestion)\n",
    "        keyterms = set(keyterms)\n",
    "        \n",
    "        #save sentences' BOW in list sen_BOW\n",
    "        sen_words = []\n",
    "        for sent in sentences:\n",
    "            sent = transform_text(sent)\n",
    "            #Docfrequency\n",
    "            sen_words.append(sent)\n",
    "            \n",
    "            #SentenceBOW\n",
    "            bow_list.append(get_BOW(sent))\n",
    "            \n",
    "            #SentenceLength\n",
    "            sent_len.append(len(sent))\n",
    "            \n",
    "            #TotalLength\n",
    "            total_len += len(sent)\n",
    "            \n",
    "        \n",
    "        #calculate doc frequency    \n",
    "        for term in keyterms:\n",
    "            for i,bow in enumerate(sen_words):\n",
    "                if term in bow:\n",
    "                    article_dic[term].append(i)\n",
    "                    \n",
    "        #Docfrequency\n",
    "        question_list.append(article_dic)\n",
    "        #SentenceBOW\n",
    "        total_sentence_bow.append(bow_list)\n",
    "        #QuestionBOW\n",
    "        total_question_bow.append(que_list)\n",
    "        #SentenceLength\n",
    "        sent_lengthes.append(sent_len)\n",
    "        #AverageLength\n",
    "        avg_lengthes.append(float(total_len)/len(sentences))\n",
    "        #\n",
    "        answer_id.append(right_answer)\n",
    "        \n",
    "    return question_list, total_sentence_bow, total_question_bow, sent_lengthes, avg_lengthes, answer_id\n",
    "\n",
    "train,test,dev = input_data()\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "punctuations = [',','\\'\\'','?','\\'','.','%','(',')',';','``']\n",
    "question_list, total_sentence_bow, total_question_bow, sent_lengthes, avg_lengthes, answer_id_list= get_Docfrequency_SentenceBOW(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def BM25(articles_index,k1,k2,b):\n",
    "    total_queries = len(total_question_bow[articles_index])\n",
    "    count = 0\n",
    "    correct_id = []\n",
    "    for index in range(len(total_question_bow[articles_index])):\n",
    "        answer_id = answer_id_list[articles_index][index]\n",
    "        guess_id = find_max_score_sentence(articles_index,index,k1,k2,b)\n",
    "        if answer_id == guess_id:\n",
    "            correct_id.append(index)\n",
    "            count += 1   \n",
    "    accurancy = float(count)/total_queries  \n",
    "    return correct_id,accurancy\n",
    "\n",
    "def find_max_score_sentence(articles_index,index,k1,k2,b):\n",
    "\n",
    "    query_dict = total_question_bow[articles_index][index]\n",
    "    max_score = 0\n",
    "    guess_sentence = 0\n",
    "    for index in range(len(total_sentence_bow[articles_index])):     \n",
    "        score = 0  \n",
    "        sentence_dict = total_sentence_bow[articles_index][index]\n",
    "        for word in query_dict:\n",
    "            document_fre_list = question_list[articles_index].get(word,None)\n",
    "            \n",
    "            \n",
    "            N = len(total_sentence_bow[articles_index])\n",
    "            n_qi = 0\n",
    "            if document_fre_list != None:\n",
    "                n_qi = len(document_fre_list)\n",
    "            else:\n",
    "                n_qi = 0\n",
    "            fi = sentence_dict.get(word,0)\n",
    "            qfi = query_dict.get(word,0)\n",
    "            dl = sent_lengthes[articles_index][index]\n",
    "            avgdl = avg_lengthes[articles_index]\n",
    "            \n",
    "            K = k1*(1-b+b*(float(dl)/avgdl)) \n",
    "            W = math.log((N-n_qi+0.5)/(n_qi+0.5))\n",
    "            R = (fi*(k1+1))/(fi+K)*qfi*(k2+1)/(qfi+k2)\n",
    "            score += W*R\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            guess_sentence = index\n",
    "    return guess_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BM25 with k1: 1.1  k2: 0  b: 0.18\n",
      "0.683639289744\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0.0\n",
    "\n",
    "k1_list = [1.1]\n",
    "k2_list = [0]\n",
    "b_list = [0.18]\n",
    "\n",
    "correct = []\n",
    "\n",
    "test_length = len(train)\n",
    "for k1 in k1_list:\n",
    "    for k2 in k2_list:\n",
    "        for b in b_list:\n",
    "            accuracy = 0.0\n",
    "            for i in range(0,test_length):\n",
    "                correct_id,i_accuracy = BM25(i,k1,k2,b)\n",
    "                accuracy += i_accuracy\n",
    "                correct.append(correct_id)\n",
    "            average_accuracy = accuracy/test_length\n",
    "            print \"Accuracy of BM25 with k1:\",k1,\" k2:\",k2,\" b:\",b\n",
    "            print average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Accuracy of BM25 with k1: 1.1  k2: 0  b: 0.18\n",
    "# 0.683639289744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import re\n",
    "import sys\n",
    "\n",
    "location_list = ['country','county']\n",
    "number_list = ['version','size','msa','far','much','year','era','ration','years','time','many','population','district','large','percent','average','day','decade','big','long']\n",
    "time_list = ['january','february','march','april','may','june','july','august','september','october','november','december','hours','minutes','miles','inches','foot','years','seasons','half']\n",
    "name_list = ['university','name','center','president','denominations','denomination','film','broadcaster','pitcher','commentator']\n",
    "\n",
    "def token(text):\n",
    "    text = text[:-1]\n",
    "    result = []\n",
    "    combo = u''\n",
    "    flag_upper = False\n",
    "    x = re.split(r'(\"|\\?|;|, |\\(|\\s|\\))\\s*', text)\n",
    "    #print x\n",
    "    for i,word in enumerate(x):\n",
    "        if word != u'' and word != u' ':\n",
    "            if word == u', ':\n",
    "                word = u','\n",
    "            if word == u'\\u2013':\n",
    "                word = u'-'\n",
    "            if word.lower() in ['in','on','after','at','both']:\n",
    "                word = word.lower()\n",
    "            if word[0].isalpha():\n",
    "                if flag_upper == False and word[0].isupper():\n",
    "                    combo = word\n",
    "                    flag_upper = True\n",
    "                elif flag_upper == False and word[0].islower():\n",
    "                    result.append(word)\n",
    "                elif flag_upper == True and word[0].isupper():\n",
    "                    combo = combo + u' ' + word\n",
    "                elif flag_upper == True and word[0].islower():\n",
    "                    result.append(combo)\n",
    "                    combo = u''\n",
    "                    result.append(word)\n",
    "                    flag_upper = False\n",
    "            else:\n",
    "                if flag_upper == True:\n",
    "                    result.append(combo)\n",
    "                    combo = u''\n",
    "                    result.append(word)\n",
    "                    flag_upper = False\n",
    "                else:\n",
    "                    result.append(word)\n",
    "    if combo != u'':\n",
    "        result.append(combo) \n",
    "    return result\n",
    "def token_question(text):\n",
    "    text = text[:-1]\n",
    "    result = []\n",
    "    combo = u''\n",
    "    flag_upper = False\n",
    "    x = re.split(r'(\"|\\?|;|, |\\(|\\s|\\))\\s*', text)\n",
    "    for i,word in enumerate(x):\n",
    "        if i == 0 and word != u'':\n",
    "            result.append(word)\n",
    "        else:\n",
    "            if word == u', ':\n",
    "                word = u','\n",
    "            if word != u'' and word != u' ':\n",
    "                if word[0].isalpha():\n",
    "                    if flag_upper == False and word[0].isupper():\n",
    "                        combo = word\n",
    "                        flag_upper = True\n",
    "                    elif flag_upper == False and word[0].islower():\n",
    "                        result.append(word)\n",
    "                    elif flag_upper == True and word[0].isupper():\n",
    "                        combo = combo + u' ' + word\n",
    "                    elif flag_upper == True and word[0].islower():\n",
    "                        result.append(combo)\n",
    "                        combo = u''\n",
    "                        result.append(word)\n",
    "                        flag_upper = False\n",
    "                else:\n",
    "                    if flag_upper == True:\n",
    "                        result.append(combo)\n",
    "                        combo = u''\n",
    "                        result.append(word)\n",
    "                        flag_upper = False\n",
    "                    else:\n",
    "                        result.append(word)\n",
    "    if combo != u'':\n",
    "        result.append(combo) \n",
    "    return result\n",
    "def transfer_pos_question(pos):\n",
    "    new_pos = []\n",
    "    for (word,wtype) in pos:\n",
    "        if word.lower() == 'what' or word.lower() == 'what\\'s':\n",
    "            new_pos.append((word,'WHAT'))\n",
    "        elif word.lower() == 'do' or word.lower() == 'does' or word.lower() == 'did':\n",
    "            new_pos.append((word,'DO'))\n",
    "        elif word.lower() in number_list:\n",
    "            new_pos.append((word,'TIME'))\n",
    "        elif word.lower() == 'is' or word.lower() == 'was' or word.lower() == 'are' or word.lower() == 'were' or word.lower() == 'be':\n",
    "            new_pos.append((word,'BE'))\n",
    "        elif word.lower() in location_list:\n",
    "            new_pos.append((word,'LOC'))\n",
    "        elif word.lower() == 'when':\n",
    "            new_pos.append((word,'WHEN'))\n",
    "        elif word.lower() == 'where':\n",
    "            new_pos.append((word,'WHERE'))\n",
    "        elif word.lower() == 'can':\n",
    "            new_pos.append((word,'CAN'))\n",
    "        elif word.lower() == 'how':\n",
    "            new_pos.append((word,'HOW'))\n",
    "        elif word.lower() == 'who' or word.lower() == 'whom' or word.lower() == 'whose'  or word.lower() == 'whos':\n",
    "            new_pos.append((word,'WHO'))\n",
    "        elif word.lower() == 'which':\n",
    "            new_pos.append((word,'WHICH'))\n",
    "        elif word.lower() in name_list:\n",
    "            new_pos.append((word,'NAME'))\n",
    "        elif word.lower() == 'define':\n",
    "            new_pos.append((word,'DEFINE'))\n",
    "        elif word.lower() == 'should':\n",
    "            new_pos.append((word,'SHOULD'))\n",
    "        elif word.lower() == 'why' or word.lower() == 'wy':\n",
    "            new_pos.append((word,'WHY'))\n",
    "        else:\n",
    "            new_pos.append((word,wtype))\n",
    "    return new_pos\n",
    "def transfer_pos_sentence(pos):\n",
    "    new_pos = []\n",
    "    pattern_1 = re.compile(r'-[0-9]+s?')\n",
    "    pattern_2 = re.compile(r'[0-9]+s?-')\n",
    "    for (word,wtype) in pos:\n",
    "        if word.lower() == 'and' or word.lower() == 'or':\n",
    "            new_pos.append((word,'POSICC'))\n",
    "        elif word.lower() == 'but' or word.lower() == 'without':\n",
    "            new_pos.append((word,'NEGCC'))\n",
    "        elif word.lower() == 'with':\n",
    "            new_pos.append((word,'WITH'))\n",
    "        elif word.lower() == 'during':\n",
    "            new_pos.append((word,'DURING'))\n",
    "        elif word.lower() == 'a' or word.lower() == 'an':\n",
    "            new_pos.append((word,'A'))\n",
    "        elif word == '\"':\n",
    "            new_pos.append((word,'\"'))\n",
    "        elif word.lower() in time_list or '$' in word or  pattern_1.search(word) or  pattern_2.search(word):\n",
    "            new_pos.append((word,'TIME'))\n",
    "        elif word == 'around':\n",
    "            new_pos.append((word,'AROUND'))\n",
    "        elif word == 'mm':\n",
    "            new_pos.append((word,'CD'))   \n",
    "        elif word == 'by':\n",
    "            new_pos.append((word,'BY'))\n",
    "        elif word[0].isupper():\n",
    "            new_pos.append((word,'UPPER'))\n",
    "        else:\n",
    "            new_pos.append((word,wtype))\n",
    "    return new_pos\n",
    "def get_continuous_chunks(text,texttype):\n",
    "    #text = text.encode('ascii','replace')\n",
    "    t = copy.deepcopy(text)\n",
    "    #print token(t)\n",
    "    if texttype==0:\n",
    "        pos = pos_tag(token(t))\n",
    "        pos = transfer_pos_sentence(pos)\n",
    "        grammar = r\"\"\"\n",
    "                    BASICN:\n",
    "                        {<UPPER>}\n",
    "                        {<NN.*>}\n",
    "                    J:\n",
    "                        {<JJ.*><VBN>}\n",
    "                        {<JJ.*><POSICC><JJ.*>}   \n",
    "                        {<JJ.*>+}\n",
    "                        {<NN.*><POS>}\n",
    "                    N:\n",
    "                        {<DT>?<BASICN>?<J>?<BASICN>+}\n",
    "                        <\\\">{<A>?<J>?<BASICN>+}<\\\">\n",
    "                    COMBON:\n",
    "                        {(<N><,>)*<N><,>?<POSICC><N>}\n",
    "                    NWC:\n",
    "                        {<N><WITH><COMBON>}\n",
    "                    \"\"\"\n",
    "    elif texttype==1:\n",
    "        #print token_question(t)\n",
    "        pos = pos_tag(token_question(t))\n",
    "        pos = transfer_pos_question(pos)\n",
    "        #print pos\n",
    "        grammar = r\"\"\"\n",
    "                    WHAT: \n",
    "                        {<WHAT>}\n",
    "                        {<WHICH>}\n",
    "                        {<DEFINE>}\n",
    "                    WHO:\n",
    "                        {<WHO>}\n",
    "                        {<WHAT><BE>?<DT>?<JJ|RB>*<NAME>}\n",
    "                        {<WHAT><JJ|RB>*<NN>+<NAME>}\n",
    "                    WHEN:\n",
    "                        {<WHICH><TIME>}\n",
    "                        {<HOW><TIME>}\n",
    "                        {<WHAT><BE>?<DT>?<JJ>?<NN>*<JJ>?<TIME>}\n",
    "                        {<WHEN>}\n",
    "                    WHERE:\n",
    "                        {<WHERE>}\n",
    "                        {<WHAT><LOC>}\n",
    "                    HOW:\n",
    "                        {<CAN>}\n",
    "                        {<DO>}\n",
    "                        {<SHOULD>}\n",
    "                        {<WHY>}\n",
    "                        {<HOW>}\n",
    "                    \n",
    "                    \"\"\"\n",
    "    elif texttype==2:\n",
    "        #when\n",
    "        pos = pos_tag(token(t))\n",
    "        pos = transfer_pos_sentence(pos)\n",
    "        #print pos\n",
    "        grammar = r\"\"\"\n",
    "                    C:\n",
    "                        {<TIME><CD>?<,><CD>}\n",
    "                        {<TIME><CD>?<,><TIME>}\n",
    "                        {<CD><TIME>}\n",
    "                        {<CD><\\.><CD>}\n",
    "                        {<AROUND><CD>+}\n",
    "                        {<RB><TIME>+}   \n",
    "                        {<JJ><TIME>+}\n",
    "                        {<AROUND><TIME>+}\n",
    "                        {<TIME>+<CD>+}\n",
    "                        {<DT>?<TIME>+}\n",
    "                        {<CD>+}      \n",
    "                    COMBOC:\n",
    "                        {<C><POSICC><C>}\n",
    "                    \"\"\"\n",
    "    elif texttype==3:\n",
    "        #when\n",
    "        pos = pos_tag(token(t))\n",
    "        pos = transfer_pos_sentence(pos)\n",
    "        #print pos\n",
    "        grammar = r\"\"\"\n",
    "                    H:\n",
    "                        {<RB><JJ><IN>?}\n",
    "                        {<IN>?<JJ.*>*<NN.*>+}\n",
    "                    HH:\n",
    "                        {<H>+}\n",
    "                    SEN:\n",
    "                        {<.*>+}\n",
    "                        }<VBD|BY|,|WITH|NEGCC|TO>+{\n",
    "                    \"\"\"\n",
    "    elif texttype==4:\n",
    "        #who\n",
    "        pos = pos_tag(token(t))\n",
    "        pos = transfer_pos_sentence(pos)\n",
    "        #print pos\n",
    "        grammar = r\"\"\"\n",
    "                    UP:\n",
    "                        {<DT>?<UPPER>}\n",
    "                    SEN:\n",
    "                        {<.*>+}\n",
    "                        }<VB.*|BY|,|WITH>+{\n",
    "                    \"\"\"\n",
    "    elif texttype == 5:\n",
    "        #cannot find\n",
    "        pos = pos_tag(token(t))\n",
    "        pos = transfer_pos_sentence(pos)\n",
    "        #print pos\n",
    "        grammar = r\"\"\"\n",
    "                    SEN:\n",
    "                        {<.*>+}\n",
    "                        }<DURING|,|WITH|NEGCC>+{\n",
    "                    \"\"\"\n",
    "    cp = nltk.RegexpParser(grammar) \n",
    "    result = []\n",
    "    poss = copy.deepcopy(pos)\n",
    "    tree = cp.parse(pos)\n",
    "    #record the position of pos\n",
    "    flag = 0\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() != 'S':\n",
    "            phrase = u''\n",
    "            for word,pos in subtree.leaves():\n",
    "                if word == ',' or word == ')':\n",
    "                    phrase = phrase + word\n",
    "                else:\n",
    "                    if len(phrase) > 0:\n",
    "                        if (phrase[-1] == '(' or phrase[-1] == ')'):\n",
    "                            phrase = phrase + word\n",
    "                        else:\n",
    "                            phrase = phrase + u' '\n",
    "                            phrase = phrase + word\n",
    "                    else:\n",
    "                        phrase = phrase + u' '\n",
    "                        phrase = phrase + word\n",
    "            result.append((subtree.label(),phrase[1:]))         \n",
    "    return poss,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NER\n",
    "'''\n",
    "time_word = ['million']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "import re\n",
    "def input_NER():\n",
    "    stanford_dir = os.path.join('stanford-ner-2016-10-31')\n",
    "    jarfile = os.path.join(stanford_dir,'stanford-ner.jar')\n",
    "    modelfile = os.path.join(stanford_dir,'classifiers/english.all.3class.distsim.crf.ser.gz')\n",
    "    return modelfile,jarfile\n",
    "model,jar = input_NER()\n",
    "st = StanfordNERTagger(model,jar)\n",
    "\n",
    "def package_NER(ner_sentences):\n",
    "    result_sentences = []\n",
    "    for ner_sentence in ner_sentences:\n",
    "        result_sentence = []\n",
    "        perv_type = u'O'\n",
    "        word = u''\n",
    "        for index,(entity,etype) in enumerate(ner_sentence):\n",
    "            if perv_type == u'O' and etype != u'O':\n",
    "                perv_type = etype\n",
    "                word = entity + u' '\n",
    "            elif word != u'':\n",
    "                if etype == u'O':\n",
    "                    result_sentence.append((word[:-1],perv_type))\n",
    "                    word = u''\n",
    "                    perv_type = u'O'\n",
    "                elif etype != perv_type:\n",
    "                    result_sentence.append((word[:-1],perv_type))\n",
    "                    word = entity + u' '\n",
    "                    perv_type = etype\n",
    "                elif etype == perv_type:\n",
    "                    if entity in ['%']:\n",
    "                        word = word[:-1] + entity + u' '\n",
    "                    else:\n",
    "                        word = word + entity + u' '\n",
    "        if word != u'':\n",
    "            result_sentence.append((word[:-1],perv_type))\n",
    "        result_sentences.append(result_sentence)      \n",
    "    return result_sentences\n",
    "\n",
    "def parse_NER(ner_sentences):\n",
    "    pattern_number = re.compile(r'([0-9]+|\\%|\\$)')\n",
    "    result_sentences = []\n",
    "    for ner_sentence in ner_sentences:\n",
    "        result_sentence = []\n",
    "        for index,(entity,etype) in enumerate(ner_sentence):\n",
    "            entity.replace(u'\\u2013',u'-')\n",
    "            entity.replace(u'\\u2014',u'-')\n",
    "            entity.replace(u'\\u2212',u'-')\n",
    "            entity.replace(u'\\u2044',u'%')\n",
    "            if etype == u'O' and entity != u'':\n",
    "                if pattern_number.search(entity) or entity in time_word:\n",
    "                    result_sentence.append((entity,u'NUMBER'))\n",
    "                elif index != 0 and entity[0].isupper():\n",
    "                    result_sentence.append((entity,u'ORGANIZATION'))\n",
    "                else:\n",
    "                    result_sentence.append((entity,etype))\n",
    "            else:\n",
    "                result_sentence.append((entity,etype))\n",
    "        result_sentences.append(result_sentence)\n",
    "        \n",
    "    return package_NER(result_sentences)\n",
    "\n",
    "def extract_NER(parse_ner_sentence,mode):\n",
    "    result = []\n",
    "    if mode == 0:\n",
    "        #PERSON\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'PERSON':\n",
    "                result.append(entity)\n",
    "    elif mode == 1:\n",
    "        #NUMBER\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'NUMBER':\n",
    "                result.append(entity)\n",
    "    elif mode == 2:\n",
    "        #LOCATION\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'LOCATION':\n",
    "                result.append(entity)\n",
    "    elif mode == 3:\n",
    "        #ORGANIZATION\n",
    "        for entity,etype in parse_ner_sentence:\n",
    "            if etype == u'ORGANIZATION':\n",
    "                result.append(entity)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_rule_1(entity,query):\n",
    "    #lower scores for content words also appear in the query\n",
    "    count = 0\n",
    "    length = len(entity)\n",
    "    for word in entity:\n",
    "        word = lemmatize(word.lower())\n",
    "        if word not in stopwords:\n",
    "            if word in query:\n",
    "                count += 1\n",
    "    if length == 0:\n",
    "        score = 0\n",
    "    else:\n",
    "        score = 1 - float(count)/length\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def get_open_class_words(query):\n",
    "    result = []\n",
    "    for index in range(len(query)):\n",
    "        if query[index] not in stopwords:\n",
    "            if query[index] not in string.punctuation:\n",
    "                result.append(query[index])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_rule_3(answer_sentence,sentence,entity,query):\n",
    "    #higher scores for closer distance between an entity and the headword\n",
    "    #step 1: using a filter to extract \"useful\" open-class words\n",
    "    results = get_open_class_words(query)\n",
    "    sent = sentence\n",
    "    original_sent = answer_sentence\n",
    "    entity_loc = []\n",
    "    query_loc = []\n",
    "    for word in entity:\n",
    "        if word in original_sent:\n",
    "            entity_loc.append(original_sent.index(word))\n",
    "    for q in results:\n",
    "        if q in sent:\n",
    "            query_loc.append(sent.index(q))\n",
    "    min_dist = len(original_sent)\n",
    "    if query_loc != []:\n",
    "        for i in query_loc:\n",
    "            for j in entity_loc:\n",
    "                dist = abs(i - j)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    \n",
    "    return 1 - float(min_dist)/len(original_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  0\n",
      "****************************************************************************************************\n",
      "Question:  What does LP stand for when it comes to time capacity?\n",
      "lists:  [u'LP', u'SP', u'EP']\n",
      "scores:  [0.5, 0.9663865546218487, 0.9411764705882353]\n",
      "pred:  SP\n",
      "label:  long playing\n",
      "****************************************************************************************************\n",
      "Question:  What are common diameters found in phonograph records?\n",
      "lists:  [u'LP', u'SP', u'EP']\n",
      "scores:  [0.7983193277310925, 0.7647058823529411, 0.7394957983193278]\n",
      "pred:  LP\n",
      "label:  12\", 10\", 7\"\n",
      "****************************************************************************************************\n",
      "Question:  What was the primary use of a phonographic disc record?\n",
      "lists:  [u'20th', u'1880s', u'1920s\\u2013by', u'1920s']\n",
      "scores:  [0.9, 0.7125, 0.6625, 0.625]\n",
      "pred:  20th\n",
      "label:  music reproduction\n",
      "****************************************************************************************************\n",
      "Question:  Which year did vinyl records leave the main steam media market?\n",
      "lists:  [u'1980s', u'1991']\n",
      "scores:  [0.9545454545454546, 0.9393939393939394]\n",
      "pred:  1980s\n",
      "label:  1991\n",
      "****************************************************************************************************\n",
      "Question:  From the 1990s to 2010s who was the primary consumer of vinyl records?\n",
      "lists:  [u'DJ']\n",
      "scores:  []\n",
      "pred:  DJ\n",
      "label:  disc jockeys (DJ)s\n",
      "****************************************************************************************************\n",
      "Question:  What was the original intent of the phonautograph?\n",
      "lists:  [u'L\\xe9on Scott', u'1857']\n",
      "scores:  [0.9512195121951219, 0.9146341463414633]\n",
      "pred:  Léon Scott\n",
      "label:  visual analysis\n",
      "****************************************************************************************************\n",
      "Question:  What format dominated the market in the late 1980s?\n",
      "lists:  [u'Internet']\n",
      "scores:  []\n",
      "pred:  Internet\n",
      "label:  digital compact disc\n",
      "****************************************************************************************************\n",
      "Question:  What was the playing surface of the blue amerbol cylinder discs made of?\n",
      "lists:  [u'Amberol', u'Blue Amberol Records']\n",
      "scores:  [0.9916666666666667, 0.8333333333333334]\n",
      "pred:  Amberol\n",
      "label:  celluloid\n",
      "****************************************************************************************************\n",
      "Question:  What types of violins worked best with early recordings?\n",
      "lists:  [u'Stroh']\n",
      "scores:  []\n",
      "pred:  Stroh\n",
      "label:  Stroh violins\n",
      "****************************************************************************************************\n",
      "Question:  What was an early took used to amplify sounds?\n",
      "lists:  [u'Western Electric']\n",
      "scores:  []\n",
      "pred:  Western Electric\n",
      "label:  vacuum tubes\n",
      "****************************************************************************************************\n",
      "Question:  What materials were discs made of in 1889-1894?\n",
      "lists:  [u'1889\\u20131894']\n",
      "scores:  []\n",
      "pred:  1889–1894\n",
      "label:  hard rubber\n",
      "****************************************************************************************************\n",
      "Question:  What was the standard material for discs around 1895?\n",
      "lists:  [u'1895']\n",
      "scores:  []\n",
      "pred:  1895\n",
      "label:  a shellac-based compound\n",
      "****************************************************************************************************\n",
      "Question:  What was Metrolite and Sav-o-flex materials primarily used for?\n",
      "lists:  [u'Decca Records', u'Deccalite', u'Metrolite', u'Merco Plastic', u'Sav-o-flex', u'DJ']\n",
      "scores:  [0.8365384615384616, 0.8653846153846154, 0.5, 0.9807692307692308, 0.5, 0.875]\n",
      "pred:  Merco Plastic\n",
      "label:  children's records\n",
      "****************************************************************************************************\n",
      "Question:  What were advantages of vinyl in the 1930's?\n",
      "lists:  [u'1930s']\n",
      "scores:  []\n",
      "pred:  1930s\n",
      "label:  light weight, relative unbreakability and low surface noise\n",
      "****************************************************************************************************\n",
      "Question:  What was a downfall of ordinary 78 rpm vinyls in household house?\n",
      "lists:  [u'78']\n",
      "scores:  []\n",
      "pred:  78\n",
      "label:  higher cost\n",
      "****************************************************************************************************\n",
      "Question:  What was one requirement issue with discs popular in Britain?\n",
      "lists:  [u'2-inch-diameter', u'51', u'Britain']\n",
      "scores:  [0.9705882352941176, 0.9509803921568627, 0.5]\n",
      "pred:  2-inch-diameter\n",
      "label:  modification of the equipment\n",
      "****************************************************************************************************\n",
      "Question:  What was the playing time common in the early 20th century?\n",
      "lists:  [u'20th']\n",
      "scores:  []\n",
      "pred:  20th\n",
      "label:  two minutes\n",
      "****************************************************************************************************\n",
      "Question:  What was the normal size disc for popular music?\n",
      "lists:  [u'10-inch 78', u'10-inch']\n",
      "scores:  [0.8125, 0.8]\n",
      "pred:  10-inch 78\n",
      "label:  10-inch\n",
      "****************************************************************************************************\n",
      "Question:  What was unique about Odeon's 1909 release of the Nutcracker Suite?\n",
      "lists:  [u'Nutcracker Suite']\n",
      "scores:  []\n",
      "pred:  Nutcracker Suite\n",
      "label:  4 double-sided discs in a specially designed package\n",
      "****************************************************************************************************\n",
      "Question:  When could record album covers first be found?\n",
      "lists:  [u'1910', u'1']\n",
      "scores:  [0.8490566037735849, 0.8867924528301887]\n",
      "pred:  1\n",
      "label:  1910\n",
      "****************************************************************************************************\n",
      "Question:  What were early record album covers made of?\n",
      "lists:  [u'1910', u'1']\n",
      "scores:  [0.8490566037735849, 0.8867924528301887]\n",
      "pred:  1\n",
      "label:  empty sleeves with a paperboard or leather cover\n",
      "****************************************************************************************************\n",
      "Question:  What is typically found on the front cover of an album?\n",
      "lists:  [u'1930s', u'78']\n",
      "scores:  [0.7386363636363636, 0.8295454545454546]\n",
      "pred:  78\n",
      "label:  artwork\n",
      "****************************************************************************************************\n",
      "Question:  When did the vinyl LP records Era begin?\n",
      "lists:  [u'12-inch', u'1949', u'78s']\n",
      "scores:  [0.9878048780487805, 0.975609756097561, 0.8170731707317074]\n",
      "pred:  12-inch\n",
      "label:  1949\n",
      "****************************************************************************************************\n",
      "Question:  What are reasons for recent releases of 78 rpm speed vinyls?\n",
      "lists:  [u'78', u'78']\n",
      "scores:  [0.5, 0.5]\n",
      "pred:  78\n",
      "label:  collectable or nostalgia purposes\n",
      "****************************************************************************************************\n",
      "Question:  What is a benefit of newer releases of 78 rpm speed vinyls?\n",
      "lists:  [u'78', u'78']\n",
      "scores:  [0.5, 0.5]\n",
      "pred:  78\n",
      "label:  higher-quality audio playback\n",
      "****************************************************************************************************\n",
      "Question:  What two songs were featured on the 1978 release by Leon Redbone in 78 rpm format?\n",
      "lists:  [u'Alabama Jubilee', u'Please Do', u'Talk About Me When I', u'Gone', u'Champagne Charlie']\n",
      "scores:  [0.972972972972973, 0.9324324324324325, 0.8918918918918919, 0.8108108108108107, 0.7567567567567568]\n",
      "pred:  Alabama Jubilee\n",
      "label:  Alabama Jubilee and Please Don't Talk About Me When I'm Gone\n",
      "****************************************************************************************************\n",
      "Question:  What record company released recordings of 'Buena' and 'Tuff Enuff' in 1980?\n",
      "lists:  [u'Stiff Records', u'King', u'Buena', u'Spanish', u'Bueno']\n",
      "scores:  [0.75, 0.872093023255814, 0.8023255813953488, 0.7790697674418605, 0.9069767441860466]\n",
      "pred:  Bueno\n",
      "label:  Stiff Records\n",
      "****************************************************************************************************\n",
      "Question:  For whom was the 1990 release of 78 rpm intended?\n",
      "lists:  [u'Rhino Records']\n",
      "scores:  []\n",
      "pred:  Rhino Records\n",
      "label:  owners of vintage jukeboxes\n",
      "****************************************************************************************************\n",
      "Question:  What caused the constant linear velocity?\n",
      "lists:  [u'World Records', u'Billing']\n",
      "scores:  [0.8787878787878788, 0.9090909090909091]\n",
      "pred:  Billing\n",
      "label:  Noel Pemberton Billing's patented add-on governor device\n",
      "****************************************************************************************************\n",
      "Question:  What gear ration creates 78.26 rpm?\n",
      "lists:  [u'3600', u'46:1', u'78.26']\n",
      "scores:  [0.9722222222222222, 0.9722222222222222, 0.5]\n",
      "pred:  3600\n",
      "label:  46:1\n",
      "****************************************************************************************************\n",
      "Question:  What was the last 78 released in the UK by RCA?\n",
      "lists:  [u'Presley', u'RCA Victor', u'I Got StungOne Night', u'RCA', u'A Mess Of BluesGirl Of My Best Friend']\n",
      "scores:  [0.9893617021276595, 0.75, 0.9574468085106382, 0.5, 0.9468085106382979]\n",
      "pred:  Presley\n",
      "label:  A Mess Of Blues/Girl Of My Best Friend\n",
      "****************************************************************************************************\n",
      "Question:  What was the last Elvis Presley single released on 78?\n",
      "lists:  [u'Presley', u'RCA Victor', u'I Got StungOne Night', u'RCA', u'A Mess Of BluesGirl Of My Best Friend']\n",
      "scores:  [0.5, 0.9361702127659575, 0.8936170212765957, 0.9361702127659575, 0.6914893617021276]\n",
      "pred:  RCA Victor\n",
      "label:  I Got Stung/One Night\n",
      "****************************************************************************************************\n",
      "Question:  What two formats replaced the 78?\n",
      "lists:  [u'World War II']\n",
      "scores:  []\n",
      "pred:  World War II\n",
      "label:  33 1⁄3 rpm (often just referred to as the 33 rpm), and the 45 rpm\n",
      "****************************************************************************************************\n",
      "Question:  What was 16 2/3 rpm speed used for?\n",
      "lists:  [u'16 2\\u20443', u'16', u'1970s']\n",
      "scores:  [0.75, 0.5, 0.6041666666666667]\n",
      "pred:  16 2⁄3\n",
      "label:  narrated publications\n",
      "****************************************************************************************************\n",
      "Question:  What record format was created for use in Chrysler automobiles?\n",
      "lists:  [u'Highway Hi-Fi', u'Chrysler', u'Chrysler']\n",
      "scores:  [0.9615384615384616, 0.5, 0.5]\n",
      "pred:  Highway Hi-Fi\n",
      "label:  Highway Hi-Fi 16 2⁄3 rpm record\n",
      "****************************************************************************************************\n",
      "Question:  What was the significance of October 26th, 1956?\n",
      "lists:  [u'Columbia Records', u'LP', u'Hall', u'Fame', u'CL', u'October']\n",
      "scores:  [0.788135593220339, 0.8728813559322034, 0.923728813559322, 0.9406779661016949, 0.9576271186440678, 0.5]\n",
      "pred:  CL\n",
      "label:  The last Columbia Records reissue of any Frank Sinatra songs on a 10-inch LP\n",
      "****************************************************************************************************\n",
      "Question:  What feature of 45s required an adapter in most home stereos?\n",
      "lists:  [u'mid-1950s', u'1960s', u'78', u'45', u'33 1\\u20443', u'16 2\\u20443', u'78', u'45s', u'U.S.']\n",
      "scores:  [0.9568965517241379, 0.9698275862068966, 0.9655172413793103, 0.9568965517241379, 0.9482758620689655, 0.9267241379310345, 0.9655172413793103, 0.5, 0.9741379310344828]\n",
      "pred:  U.S.\n",
      "label:  larger center hole.\n",
      "****************************************************************************************************\n",
      "Question:  What feature was found on more home stereos that allowed continuous play between records?\n",
      "lists:  [u'mid-1950s', u'1960s', u'78', u'45', u'33 1\\u20443', u'16 2\\u20443', u'78', u'45s', u'U.S.']\n",
      "scores:  [0.9568965517241379, 0.9698275862068966, 0.9655172413793103, 0.9568965517241379, 0.9482758620689655, 0.9267241379310345, 0.9655172413793103, 0.8793103448275862, 0.853448275862069]\n",
      "pred:  1960s\n",
      "label:  changer\n",
      "****************************************************************************************************\n",
      "Question:  What format was less common but could sometimes be found on home stereos?\n",
      "lists:  [u'mid-1950s', u'1960s', u'78', u'45', u'33 1\\u20443', u'16 2\\u20443', u'78', u'45s', u'U.S.']\n",
      "scores:  [0.9612068965517242, 0.9741379310344828, 0.9655172413793103, 0.9741379310344828, 0.9870689655172413, 0.9956896551724138, 0.9655172413793103, 0.7370689655172413, 0.7112068965517242]\n",
      "pred:  16 2⁄3\n",
      "label:  16 2⁄3 rpm\n",
      "****************************************************************************************************\n",
      "Question:  What were the plastic inserts which would adapt 45s to the smaller spindle of an LP player called?\n",
      "lists:  [u'LP']\n",
      "scores:  []\n",
      "pred:  LP\n",
      "label:  spider\n",
      "****************************************************************************************************\n",
      "Question:  How many spiders were sold in the 45 rpm heydays?\n",
      "lists:  [u'1960s', u'45']\n",
      "scores:  [0.9722222222222222, 0.5]\n",
      "pred:  1960s\n",
      "label:  tens of millions per year\n",
      "****************************************************************************************************\n",
      "Question:  What term was coined to differentiate better sounding products in the 1920s?\n",
      "lists:  [u'1920s']\n",
      "scores:  []\n",
      "pred:  1920s\n",
      "label:  high fidelity\n",
      "****************************************************************************************************\n",
      "Question:  What magazines provided reviews for audio equipment?\n",
      "lists:  [u'Fidelity', u'Audio']\n",
      "scores:  [0.9545454545454546, 0.5]\n",
      "pred:  Fidelity\n",
      "label:  High Fidelity and Audio\n",
      "****************************************************************************************************\n",
      "Question:  What happened in 1958 that changed the home music scene?\n",
      "lists:  [u'1949', u'1958']\n",
      "scores:  [0.8214285714285714, 0.5]\n",
      "pred:  1949\n",
      "label:  variety of improvements in recording and playback technologies\n",
      "****************************************************************************************************\n",
      "Question:  During what years did the term HiFi take off with engineers?\n",
      "lists:  [u'1930s', u'1940s']\n",
      "scores:  [0.8611111111111112, 0.8055555555555556]\n",
      "pred:  1930s\n",
      "label:  1930s and 1940s\n",
      "****************************************************************************************************\n",
      "Question:  What term would be used when one said they produced perfect sound reproduction?\n",
      "lists:  [u'1920s']\n",
      "scores:  []\n",
      "pred:  1920s\n",
      "label:  high fidelity\n",
      "****************************************************************************************************\n",
      "Question:  What did Alan Blumlein event?\n",
      "lists:  [u'EMI']\n",
      "scores:  []\n",
      "pred:  EMI\n",
      "label:  stereophonic record system\n",
      "****************************************************************************************************\n",
      "Question:  Who developed the 3-to-2 mix to create lifelike recordings?\n",
      "lists:  [u'Wilma Cozart Fine']\n",
      "scores:  []\n",
      "pred:  Wilma Cozart Fine\n",
      "label:  Mercury\n",
      "****************************************************************************************************\n",
      "Question:  What technique were used to reduce inner-groove distortion?\n",
      "lists:  [u'CBS DisComputer', u'Teldec Direct Metal Mastering']\n",
      "scores:  [0.8461538461538461, 0.9423076923076923]\n",
      "pred:  Teldec Direct Metal Mastering\n",
      "label:  CBS DisComputer and Teldec Direct Metal Mastering\n",
      "****************************************************************************************************\n",
      "Question:  When was the Disco Eye-Cued System developed?\n",
      "lists:  [u'1970s', u'12-inch', u'1978', u'1980']\n",
      "scores:  [0.9090909090909091, 0.8863636363636364, 0.7954545454545454, 0.75]\n",
      "pred:  1970s\n",
      "label:  late 1970s\n",
      "****************************************************************************************************\n",
      "Question:  What company out of Japan offered laser turntables that read vinyl discs optically?\n",
      "lists:  [u'ELPJ', u'Japanese-based']\n",
      "scores:  [0.9166666666666667, 0.9791666666666667]\n",
      "pred:  Japanese-based\n",
      "label:  ELPJ\n",
      "****************************************************************************************************\n",
      "Question:  What is a typical max playing time of an LP?\n",
      "lists:  [u'30', u'22']\n",
      "scores:  [0.9459459459459459, 0.8783783783783784]\n",
      "pred:  30\n",
      "label:  forty-five minutes\n",
      "****************************************************************************************************\n",
      "Question:  Which format held recordings ranging from 10 to 15 minutes?\n",
      "lists:  [u'EP']\n",
      "scores:  []\n",
      "pred:  EP\n",
      "label:  7-inch EP\n",
      "****************************************************************************************************\n",
      "Question:  What was a normal play time per side for LPs?\n",
      "lists:  [u'30', u'22']\n",
      "scores:  [0.972972972972973, 0.9054054054054054]\n",
      "pred:  30\n",
      "label:  22 minutes\n",
      "****************************************************************************************************\n",
      "Question:  PeeWee the Piccolo was what?\n",
      "lists:  [u'PeeWee', u'Piccolo', u'RCA', u'Dec.', u'Price']\n",
      "scores:  [0.5, 0.5, 0.975, 0.725, 0.7125]\n",
      "pred:  RCA\n",
      "label:  The first 45 rpm record created for sale\n",
      "****************************************************************************************************\n",
      "Question:  When did RCA release the 45?\n",
      "lists:  [u'1949', u'45', u'7', u'33 13']\n",
      "scores:  [0.9375, 0.5, 0.875, 0.8333333333333334]\n",
      "pred:  1949\n",
      "label:  March 1949\n",
      "****************************************************************************************************\n",
      "Question:  What is the most used material for modern audiophile vinyl releases?\n",
      "lists:  [u'180\\u2013220']\n",
      "scores:  []\n",
      "pred:  180–220\n",
      "label:  New or \"virgin\" heavy/heavyweight (180–220 g) vinyl\n",
      "****************************************************************************************************\n",
      "Question:  What material is on a direct metal mastering disc?\n",
      "lists:  [u'DMM']\n",
      "scores:  []\n",
      "pred:  DMM\n",
      "label:  copper\n",
      "****************************************************************************************************\n",
      "Question:  In which novel does 'Whiteman's Lady of the Evening\" record get broken?\n",
      "lists:  [u'Appointment', u'Lady', u'Evening']\n",
      "scores:  [0.9642857142857143, 0.5, 0.5]\n",
      "pred:  Appointment\n",
      "label:  John O'Hara novel, Appointment in Samarra\n",
      "****************************************************************************************************\n",
      "Question:  In Blackboard Jungle what record breaking mention is made?\n",
      "lists:  [u'Blackboard Jungle']\n",
      "scores:  []\n",
      "pred:  Blackboard Jungle\n",
      "label:  teacher's collection of 78 rpm jazz records is smashed\n",
      "****************************************************************************************************\n",
      "Question:  How much vinyl can be found at the start of an LP?\n",
      "lists:  [u'510', u'200\\u2013210']\n",
      "scores:  [0.9642857142857143, 0.8333333333333334]\n",
      "pred:  510\n",
      "label:  510 mm\n",
      "****************************************************************************************************\n",
      "Question:  On which recording types were pre-emphasis used most in the 1920s?\n",
      "lists:  [u'Hz']\n",
      "scores:  []\n",
      "pred:  Hz\n",
      "label:  78 rpm and 33 1⁄3 rpm\n",
      "****************************************************************************************************\n",
      "Question:  What bass settings were needed to eliminate hum?\n",
      "lists:  [u'Hz']\n",
      "scores:  []\n",
      "pred:  Hz\n",
      "label:  below 100 Hz\n",
      "****************************************************************************************************\n",
      "Question:  How far back could these recording practices be traced?\n",
      "lists:  [u'1925', u'1950s']\n",
      "scores:  [0.868421052631579, 0.9342105263157895]\n",
      "pred:  1950s\n",
      "label:  1925\n",
      "****************************************************************************************************\n",
      "Question:  Whom wrote the publication outlining the New Orthophonic curve?\n",
      "lists:  [u'Moyer']\n",
      "scores:  []\n",
      "pred:  Moyer\n",
      "label:  R.C. Moyer\n",
      "****************************************************************************************************\n",
      "Question:  What benefit did the use of the Wente style condenser microphone offer?\n",
      "lists:  [u'Wente', u'Western Electric']\n",
      "scores:  [0.5, 0.9625]\n",
      "pred:  Western Electric\n",
      "label:  brilliant midrange\n",
      "****************************************************************************************************\n",
      "Question:  What was a benefit of early radio recordings?\n",
      "lists:  [u'1925']\n",
      "scores:  []\n",
      "pred:  1925\n",
      "label:  microphones and amplifiers\n",
      "****************************************************************************************************\n",
      "Question:  When would you have first found the moving coil microphone?\n",
      "lists:  [u'1930', u'1932']\n",
      "scores:  [0.8947368421052632, 0.6842105263157895]\n",
      "pred:  1930\n",
      "label:  around 1930\n",
      "****************************************************************************************************\n",
      "Question:  What was a benefit of the use of magnetic pickup cartridge?\n",
      "lists:  [u'General Electric']\n",
      "scores:  []\n",
      "pred:  General Electric\n",
      "label:  high quality cuts\n",
      "****************************************************************************************************\n",
      "Question:  When was the Western Electric System introduced?\n",
      "lists:  [u'1930s']\n",
      "scores:  []\n",
      "pred:  1930s\n",
      "label:  early 1930s\n",
      "****************************************************************************************************\n",
      "Question:  What two companies worked together to develop the Western Electric System?\n",
      "lists:  [u'Bell Telephone Laboratories', u'Western Electric', u'Western Electric Wide Range System', u'The New Voice', u'Action']\n",
      "scores:  [0.9696969696969697, 0.5, 0.7, 0.9545454545454546, 0.8939393939393939]\n",
      "pred:  Bell Telephone Laboratories\n",
      "label:  Bell Telephone Laboratories and Western Electric\n",
      "****************************************************************************************************\n",
      "Question:  What were the top licensees of the Western Electric system in the 1930s?\n",
      "lists:  [u'World Broadcasting System', u'Associated Music Publishers', u'AMP', u'Western Electric']\n",
      "scores:  [0.8333333333333334, 0.9772727272727273, 0.9431818181818181, 0.5]\n",
      "pred:  Associated Music Publishers\n",
      "label:  World Broadcasting System and Associated Music Publishers\n",
      "****************************************************************************************************\n",
      "Question:  Who was responsible for 2/3 of all recordings in the 1930s?\n",
      "lists:  [u'World Broadcasting System', u'Associated Music Publishers', u'AMP', u'Western Electric']\n",
      "scores:  [0.7159090909090908, 0.7613636363636364, 0.7840909090909091, 0.8863636363636364]\n",
      "pred:  Western Electric\n",
      "label:  World Broadcasting System and Associated Music Publishers\n",
      "****************************************************************************************************\n",
      "Question:  What kind of recordings worked best for pop music?\n",
      "lists:  [u'LP', u'FM']\n",
      "scores:  [0.9791666666666667, 0.9375]\n",
      "pred:  LP\n",
      "label:  45 rpm\n",
      "****************************************************************************************************\n",
      "Question:  What was a major cause of declined vinyl sales?\n",
      "lists:  [u'1988', u'1991']\n",
      "scores:  [0.95, 0.95]\n",
      "pred:  1988\n",
      "label:  major label distributors restricted their return policies\n",
      "****************************************************************************************************\n",
      "Question:  What was unique to vinyl sales in 2014?\n",
      "lists:  [u'2014']\n",
      "scores:  []\n",
      "pred:  2014\n",
      "label:  was the only physical music medium with increasing sales with relation to the previous year\n",
      "****************************************************************************************************\n",
      "Question:  Who sold 34,000 vinyl records in 1994?\n",
      "lists:  [u'Pearl Jam', u'Vitalogy']\n",
      "scores:  [0.8913043478260869, 0.9347826086956521]\n",
      "pred:  Vitalogy\n",
      "label:  Pearl Jam\n",
      "0.201183431953\n",
      "0.254437869822\n"
     ]
    }
   ],
   "source": [
    "total_count = 0.0\n",
    "total_question = 0.0\n",
    "c = 0.0\n",
    "for index in range(len(train)):#range(len(train)):\n",
    "    print \"processing: \",index\n",
    "    article = train[index]\n",
    "    qas = article['qa']\n",
    "    sentences = article['sentences']\n",
    "    token_sentences = copy.deepcopy(sentences)\n",
    "    for i in range(len(sentences)):\n",
    "        token_sentences[i] = nltk.word_tokenize(token_sentences[i])\n",
    "    ner_sentences = st.tag_sents(token_sentences)\n",
    "    parse_ner_sentences = parse_NER(ner_sentences)\n",
    "    total_question += len(correct[index])\n",
    "    for i in correct[index]:\n",
    "        answer_list = []\n",
    "        qa = qas[i]\n",
    "        flag = False\n",
    "        text_question = qa['question']\n",
    "        answer = qa['answer']\n",
    "        answer_sentence_id = qa['answer_sentence']\n",
    "        pos,result = get_continuous_chunks(text_question,1)\n",
    "        #print pos\n",
    "        if result != []:\n",
    "            wtype,word = result[0]         \n",
    "            #print '^'*100\n",
    "            #print wtype\n",
    "            if wtype == 'WHAT':               \n",
    "                answer_list = extract_NER(parse_ner_sentences[answer_sentence_id],3)\n",
    "                if answer_list == []:\n",
    "                    answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],0)\n",
    "                    answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],1)\n",
    "                    answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],2)\n",
    "                if qa['answer'] in answer_list:\n",
    "                    flag = True\n",
    "                    total_count += 1\n",
    "            elif wtype == 'WHEN':\n",
    "                answer_list = extract_NER(parse_ner_sentences[answer_sentence_id],1)\n",
    "                if qa['answer'] in answer_list:\n",
    "                    flag = True\n",
    "                    total_count += 1\n",
    "            elif wtype == 'WHO':\n",
    "                answer_list = extract_NER(parse_ner_sentences[answer_sentence_id],0)\n",
    "                if answer_list == []:\n",
    "                    answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],2)\n",
    "                    answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],3)\n",
    "                if qa['answer'] in answer_list:\n",
    "                    flag = True\n",
    "                    total_count += 1\n",
    "\n",
    "            elif wtype == 'WHERE':\n",
    "                answer_list = extract_NER(parse_ner_sentences[answer_sentence_id],2)\n",
    "                if answer_list == []:\n",
    "                    answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],0)\n",
    "                    answer_list += extract_NER(parse_ner_sentences[answer_sentence_id],3)\n",
    "                if qa['answer'] in answer_list:\n",
    "                    flag = True\n",
    "                    total_count += 1\n",
    "            \n",
    "#             if flag == True:\n",
    "# #                 print '*'*100\n",
    "# #                 print text_question\n",
    "# #                 print wtype\n",
    "#                 print '^'*100\n",
    "#                 print text_question\n",
    "#                 print wtype\n",
    "#                 print sentences[answer_sentence_id]\n",
    "#                 print parse_ner_sentences[answer_sentence_id]\n",
    "#                 print 'A: ',answer\n",
    "#                 print answer_list\n",
    "#             elif wtype in ['WHAT','WHEN','WHO','WHERE'] and flag == False:\n",
    "#                 print '^'*100\n",
    "#                 print text_question\n",
    "#                 print wtype\n",
    "#                 print sentences[answer_sentence_id]\n",
    "#                 print parse_ner_sentences[answer_sentence_id]\n",
    "#                 print 'A: ',answer\n",
    "#                 print answer_list\n",
    "#         else:\n",
    "#             print '^'*100\n",
    "\n",
    "        if answer_list != []:\n",
    "            query = copy.deepcopy(text_question)\n",
    "            query = nltk.word_tokenize(query)\n",
    "            #token the answer sentence and copy it for further usage\n",
    "            answer_sentence = sentences[answer_sentence_id]\n",
    "            answer_sentence = nltk.word_tokenize(answer_sentence)\n",
    "            sentence = copy.deepcopy(answer_sentence)\n",
    "\n",
    "            for query_index in range(len(query)):\n",
    "                query[query_index] = lemmatize(query[query_index].lower())\n",
    "\n",
    "            for sent_index in range(len(sentence)):\n",
    "                sentence[sent_index] = lemmatize(sentence[sent_index].lower())\n",
    "\n",
    "            scores_1 = []\n",
    "            scores_3 = []\n",
    "            scores = []\n",
    "            if len(answer_list) == 1:\n",
    "                answer = answer_list[0]\n",
    "            else:\n",
    "                for entity in answer_list:\n",
    "                    entity = nltk.word_tokenize(entity) \n",
    "                    score1 = rank_rule_1(entity,query)\n",
    "                    scores_1.append(score1)\n",
    "                    #answer_sentence is the original version and sentence is preprocessed\n",
    "                    score3 = rank_rule_3(answer_sentence,sentence,entity,query)\n",
    "                    scores_3.append(score3)\n",
    "                    w1 = 0.5\n",
    "                    w3 = 1 - w1\n",
    "                    total = w1 * score1 + w3 * score3\n",
    "                    scores.append(total)\n",
    "                answer = answer_list[scores.index(max(scores))]\n",
    "                \n",
    "            if qa['answer'] == answer:\n",
    "                c += 1\n",
    "#             else:\n",
    "#                 print '*'*100\n",
    "#                 print 'Question: ',text_question\n",
    "#                 print 'lists: ',answer_list\n",
    "#                 print 'scores: ',scores\n",
    "#                 print 'pred: ',answer\n",
    "#                 print 'label: ',qa['answer']\n",
    "print c/total_question\n",
    "print total_count/total_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.118628417938\n",
    "# 0.279625626928"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
